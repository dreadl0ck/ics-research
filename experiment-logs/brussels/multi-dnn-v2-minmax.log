2020-02-06 22:38:54.323996: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-06 22:38:54.324051: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-06 22:38:54.324058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-06 22:38:54.813283: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-06 22:38:54.813303: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-06 22:38:54.813318: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-06 22:38:54.813421: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-06 22:38:54.833871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-06 22:38:54.834268: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ca6cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 22:38:54.834303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=============================
        TRAINING v0.4
=============================
Date: 2020-02-06 22:38:54.809978
[33m[INFO] using Sequential Dense layers[0m
[INFO] adding core layer 0
[INFO] created DNN
[33m[INFO] epoch 1/10[0m
[33m[INFO] loading file 1-1/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5601 - tp: 55424.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 24576.0000 - accuracy: 0.9386 - precision: 1.0000 - recall: 0.6928 - auc: 1.0000 - val_loss: 0.1327 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0637 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0271 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0320 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.7138 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1596 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8761 - val_loss: 0.7032 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6961 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8823 - val_loss: 0.6937 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6926 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8833 - val_loss: 0.6922 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4455 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9610 - val_loss: 0.1733 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3144 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9765 - val_loss: 1.1745 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7224 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6914 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4512 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1764 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6963 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8908 - val_loss: 0.6947 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5935 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9302 - val_loss: 0.3257 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0641 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0295e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6519e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3138e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3231e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0171e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3272e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6587 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9482 - val_loss: 2.2805 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6726 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9273 - val_loss: 0.3355 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5269 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9452 - val_loss: 0.7024 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6549 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9103 - val_loss: 0.5353 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0834 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0108 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6957e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5158e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6445e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3803e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0952e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4828e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4573 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5013 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8067 - val_loss: 1.5007 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-001-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9147 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9098 - val_loss: 0.6570 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9103 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0457 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0032 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.2416e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.3901e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8010e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6412e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5708e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4955 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9607 - val_loss: 0.6582 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4947 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9546 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-001-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0928 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0198 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7823e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6648e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9238e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7100e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9165e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0174 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2944 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8943 - val_loss: 0.1482 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0627 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0240 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0131 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7466e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3666e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7570e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0310e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3881e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1618e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7113e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9875e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2127 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2507 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3106 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3556e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6814e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9476e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1446 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6390 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8662 - val_loss: 0.8109 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6770 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9103 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5275 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9457 - val_loss: 0.2474 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0531 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0141 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0075 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.1131e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1764e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1902e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2397e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3105e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1536e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.2358e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3391e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8614e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.2609 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.3836 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.0461 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-001-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.8729 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 5.7127 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8114 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 2.8118e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5988e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4638e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3945e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3267e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2335e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1098e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8954e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6259e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2711e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0833e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1540 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2598 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7738 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4977 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-001-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5718 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9518 - val_loss: 1.5432 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8051 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9056 - val_loss: 0.6653 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9047 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2718 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9831 - val_loss: 0.0712 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0225 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0073 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6656e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3076e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7200e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7001 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.0988 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.7877 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.7023 - val_loss: 0.0346 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0288 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1191 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5274 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9546 - val_loss: 0.4747 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4761 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9543 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2044 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9877 - val_loss: 0.0503 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0160 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9722e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0928e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3902e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2433e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.2902e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8146e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2342e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1682e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7676 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3334 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9443 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7356 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5364 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7144 - val_loss: 2.3752 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.4086 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8825 - val_loss: 0.7576 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6998 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8826 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-001-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6469 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9137 - val_loss: 0.4218 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0808 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5679e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4479e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6073e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3625e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9914e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1722e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4494e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5136e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4747 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.2955 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-001-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1196 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8998 - val_loss: 0.6618 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9111 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 3.5207 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6962 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7337 - val_loss: 4.7514 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8803 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7324 - val_loss: 3.0027 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1731 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7696 - val_loss: 1.3530 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9090 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8821 - val_loss: 0.7072 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-001-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6822 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9110 - val_loss: 0.6674 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6551 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9102 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6505 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9113 - val_loss: 0.6508 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.6511 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6523 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9105 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6497 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9114 - val_loss: 0.6507 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9113 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9113 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9116 - val_loss: 0.6501 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-001-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9112 - val_loss: 0.6511 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9105 - val_loss: 0.6507 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6491 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-001-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9102 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9113 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9103 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-001-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9114 - val_loss: 0.6514 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6529 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9113 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9114 - val_loss: 0.6504 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-001-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6499 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 1/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9102 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6521 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-001-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.651811322593689[0m
[33m[INFO] epoch 2/10[0m
[33m[INFO] loading file 1-1/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0832 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0204 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0108 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6599 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1135 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8800 - val_loss: 0.6943 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6916 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8825 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8824 - val_loss: 0.6914 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4441 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9613 - val_loss: 0.1654 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3142 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1782 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7238 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8819 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4509 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1696 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6957 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8915 - val_loss: 0.6947 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5937 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9305 - val_loss: 0.3247 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0644 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0755e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6781e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3266e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3041e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.8194e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1722e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6609 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9479 - val_loss: 2.2899 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6709 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9279 - val_loss: 0.3378 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5268 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9454 - val_loss: 0.7035 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6550 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9102 - val_loss: 0.5266 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0815 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5594e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4467e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6063e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3613e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9871e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1722e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4481e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4607 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4907 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8069 - val_loss: 1.4927 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-002-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9090 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9102 - val_loss: 0.6563 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4800 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9543 - val_loss: 0.1964 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0442 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9796e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2365e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7236e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.5966e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3443e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4942 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9614 - val_loss: 0.6512 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4938 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9547 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-002-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0916 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0193 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7918e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6713e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9274e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7131e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9403e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0121 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2794 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8955 - val_loss: 0.1551 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0642 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7597e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3757e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7641e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0345e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4000e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1709e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7209e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9875e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2125 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2529 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3118 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3407e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6743e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9442e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1448 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6386 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8661 - val_loss: 0.8092 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6771 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9101 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5277 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9453 - val_loss: 0.2484 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0534 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0141 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0075 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.1462e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1955e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1592e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3076e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3279e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.5337e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.1341e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6133e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2016e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 11.1970 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.4193 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 9.0859 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-002-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9117 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.7517 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4122 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 8.4277e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.4324e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9219e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3767e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0159e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8335e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.6941e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6000e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5034e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3735e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2053e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1841 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2970 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8131 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.5122 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-002-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5922 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9495 - val_loss: 1.6165 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8278 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9057 - val_loss: 0.6652 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9049 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2734 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9829 - val_loss: 0.0735 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0232 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8348e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4054e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7761e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7465 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.3085 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9937 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6882 - val_loss: 0.0252 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0218 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1204 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5399 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9547 - val_loss: 0.4748 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2046 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0509 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0161 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0052 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9595e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0880e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3874e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2445e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3029e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8146e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2383e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1682e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7425 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3004 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9108 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.6992 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5000 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7173 - val_loss: 2.3396 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3823 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8827 - val_loss: 0.7518 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6991 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8824 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-002-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6471 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9136 - val_loss: 0.4295 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0815 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6262e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4872e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6321e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3756e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0681e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2199e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4729e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2875e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5796e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4803 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3411 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-002-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1477 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8982 - val_loss: 0.6638 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 3.5217 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6895 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7337 - val_loss: 4.7425 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8713 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7324 - val_loss: 2.9924 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1651 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7700 - val_loss: 1.3465 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9069 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8822 - val_loss: 0.7074 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-002-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6824 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6675 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6535 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9102 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9103 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6505 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9105 - val_loss: 0.6525 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6513 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9115 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9108 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6506 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6498 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6506 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9115 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-002-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-002-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9115 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-002-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6502 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9115 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-002-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9108 - val_loss: 0.6499 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 2/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-002-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517616979598999[0m
[33m[INFO] epoch 3/10[0m
[33m[INFO] loading file 1-1/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0818 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6543 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1082 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8803 - val_loss: 0.6940 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6915 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8827 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6914 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8822 - val_loss: 0.6914 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4446 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9614 - val_loss: 0.1691 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3141 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1498 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7209 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8817 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4504 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1747 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6962 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8912 - val_loss: 0.6940 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5939 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9300 - val_loss: 0.3256 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0647 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0165 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0088 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.1228e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7067e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3437e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3529e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.2506e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4822e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6584 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9484 - val_loss: 2.2774 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6710 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9279 - val_loss: 0.3448 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5269 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9453 - val_loss: 0.7035 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9102 - val_loss: 0.5304 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0826 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6629e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5063e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6432e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3815e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1021e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4833e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4575 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5026 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8060 - val_loss: 1.5057 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-003-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9156 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9101 - val_loss: 0.6570 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9104 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4804 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9541 - val_loss: 0.2041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0457 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0124 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0066 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0032 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.2678e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.4036e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8141e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6510e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.6304e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4826 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9625 - val_loss: 0.6333 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4913 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9545 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-003-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9541 - val_loss: 0.4803 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0911 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0189 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0084 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0019 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.5370e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.5259e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8499e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6705e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.7257e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0237 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2743 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8963 - val_loss: 0.1561 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0644 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0242 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7824e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3923e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7725e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0398e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4358e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1872e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6689e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7687e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9981e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2123 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2399 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3044 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0017 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4669e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7351e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9767e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1426 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6282 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8668 - val_loss: 0.8062 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6757 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5279 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9455 - val_loss: 0.2415 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0520 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0138 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0182e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1335e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1730e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3434e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3437e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0105e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.3986e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.2544e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.0000e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 11.2317 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.4631 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 9.1283 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-003-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9543 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.7929 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4350 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 5.3762e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8394e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.0636e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.7885e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5987e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5126e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4438e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3804e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.3246e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2050e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.0623e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2032 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.3218 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8328 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.5184 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-003-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6004 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9487 - val_loss: 1.6424 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8369 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9054 - val_loss: 0.6655 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9047 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2733 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9827 - val_loss: 0.0737 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0232 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8324e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4210e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7880e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7587 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.3650 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.0359 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6856 - val_loss: 0.0236 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0206 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1208 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5431 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9544 - val_loss: 0.4750 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9541 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2048 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0512 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0164 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1601e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1917e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4592e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2850e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5349e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9338e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3095e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2040e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7457 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3051 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9148 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7033 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5025 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7176 - val_loss: 2.3397 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3804 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8835 - val_loss: 0.7499 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6987 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8826 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-003-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6472 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9134 - val_loss: 0.4219 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0810 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6250e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5063e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6437e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3815e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1036e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4838e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2994e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6128e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4803 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3284 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-003-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1356 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8989 - val_loss: 0.6634 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9113 - val_loss: 0.6517 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 3.5211 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6963 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7336 - val_loss: 4.7497 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8778 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7323 - val_loss: 2.9989 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1696 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7699 - val_loss: 1.3504 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9084 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8820 - val_loss: 0.7075 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-003-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6824 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6675 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9112 - val_loss: 0.6497 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6501 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6505 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6497 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6513 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9114 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9102 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6524 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6503 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9115 - val_loss: 0.6508 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-003-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6516 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6529 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-003-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6519 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6509 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-003-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9112 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6529 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9102 - val_loss: 0.6503 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9114 - val_loss: 0.6505 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-003-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 3/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-003-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517609174728394[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517609174728394  <  0.001
[33m[INFO] epoch 4/10[0m
[33m[INFO] loading file 1-1/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0822 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6821 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1209 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8799 - val_loss: 0.6939 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6915 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8828 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8824 - val_loss: 0.6915 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4442 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9612 - val_loss: 0.1691 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3142 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9764 - val_loss: 1.1688 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7215 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8822 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4511 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1712 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6957 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8914 - val_loss: 0.6942 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5938 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9301 - val_loss: 0.3237 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0643 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0917e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7055e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3425e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3494e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.2182e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4464e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6487 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9490 - val_loss: 2.2282 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9279 - val_loss: 0.3408 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5270 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9449 - val_loss: 0.6984 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9101 - val_loss: 0.5268 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0813 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0199 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5420e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4634e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6182e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3684e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0254e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1961e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4598e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4596 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5253 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8043 - val_loss: 1.5256 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-004-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9274 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9097 - val_loss: 0.6577 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9102 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4799 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9543 - val_loss: 0.2014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0445 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9558e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2542e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7462e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6107e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4158e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4920 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9615 - val_loss: 0.6466 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4929 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9547 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-004-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9538 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0931 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9966 - val_loss: 0.0198 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0088 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9347e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7532e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9822e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7491e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1429e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0180 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2910 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8947 - val_loss: 0.1501 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0632 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8181e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4135e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7832e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0464e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4716e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2071e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6808e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.8297e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0136e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2116 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2480 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3080 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4157e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7112e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9651e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1434 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6337 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8668 - val_loss: 0.8071 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6763 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9104 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5277 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9452 - val_loss: 0.2456 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0525 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0585e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1657e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1583e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2921e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3391e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4158e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.1260e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0173e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5693e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 11.1713 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.3971 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 9.0639 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-004-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.8897 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.7303 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4012 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 6.6755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.6357e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6001e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2213e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9683e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8517e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7537e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6705e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.5749e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4484e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2650e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1843 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2973 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.8100 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.5101 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-004-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5891 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9498 - val_loss: 1.6048 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8270 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9048 - val_loss: 0.6655 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9050 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2722 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0727 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0228 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7180e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3542e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7522e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7471 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.3224 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.0015 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6880 - val_loss: 0.0249 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0216 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1205 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5408 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9544 - val_loss: 0.4748 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9543 - val_loss: 0.4737 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2044 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9877 - val_loss: 0.0515 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0161 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0052 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9533e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0845e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3965e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2516e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3425e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8385e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2505e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1802e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7645 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3315 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9414 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7310 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5287 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7151 - val_loss: 2.3662 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.4025 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8827 - val_loss: 0.7568 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6996 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8828 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-004-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6471 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9130 - val_loss: 0.4211 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0809 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6294e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5087e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6450e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3827e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1077e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4850e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2994e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6168e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4795 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3333 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-004-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1417 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8984 - val_loss: 0.6637 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 3.5190 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6847 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7337 - val_loss: 4.7366 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8661 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7325 - val_loss: 2.9882 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1595 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7702 - val_loss: 1.3418 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9051 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8827 - val_loss: 0.7067 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-004-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6820 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6674 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9103 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9113 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6513 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6518 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6505 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6510 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6497 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-004-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9105 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9103 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6490 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-004-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-004-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9106 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9105 - val_loss: 0.6497 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9102 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6527 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9110 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9112 - val_loss: 0.6504 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-004-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9111 - val_loss: 0.6527 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6500 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 4/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-004-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6518572517395019[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6518572517395019  <  0.001
[33m[INFO] epoch 5/10[0m
[33m[INFO] loading file 1-1/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0805 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0199 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0105 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6838 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1189 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8802 - val_loss: 0.6940 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6915 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8828 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8823 - val_loss: 0.6914 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4445 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9610 - val_loss: 0.1694 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3142 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1464 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7200 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8823 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4505 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1716 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6960 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8914 - val_loss: 0.6948 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5936 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9302 - val_loss: 0.3385 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0664 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0168 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0089 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0043 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.2752e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8021e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3926e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3386e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0213e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2914e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6706 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9470 - val_loss: 2.3525 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6794 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9280 - val_loss: 0.3426 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9447 - val_loss: 0.7008 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9101 - val_loss: 0.5271 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0819 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6225e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5051e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6429e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3815e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1010e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4830e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4576 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5104 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8058 - val_loss: 1.5121 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-005-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9191 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9102 - val_loss: 0.6567 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9102 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.1991 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0442 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0119 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9355e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2421e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7391e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6070e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3920e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4839 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9619 - val_loss: 0.6374 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4910 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9549 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-005-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0922 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0196 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8609e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7102e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9595e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7361e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0714e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0092 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2783 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8956 - val_loss: 0.1546 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0641 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8014e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4032e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7784e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0432e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4477e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1975e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6689e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.8000e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0046e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2121 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2534 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3134 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.2838e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6374e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9216e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1469 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6425 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8658 - val_loss: 0.8124 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6772 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5279 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9452 - val_loss: 0.2435 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0525 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0140 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0999e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1883e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1568e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3053e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3424e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.2013e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6630e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.4928e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1754e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.9190 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.1317 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.7976 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-005-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6241 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.4665 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2452 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 7.9867e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.3670e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5192e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2226e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0186e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.9135e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8040e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.6503e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4583e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.0981e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6358e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1519 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2556 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7724 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4971 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-005-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5707 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9519 - val_loss: 1.5377 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8040 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9052 - val_loss: 0.6654 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9048 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2729 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9829 - val_loss: 0.0719 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0229 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7550e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3528e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7427e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7432 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.2927 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9764 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6894 - val_loss: 0.0259 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0223 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1203 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5383 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9548 - val_loss: 0.4747 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9543 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2051 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9873 - val_loss: 0.0528 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0165 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1090e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1417e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4070e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2540e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3601e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8504e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2604e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1802e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7568 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3209 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9380 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7253 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5218 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7157 - val_loss: 2.3608 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3975 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8827 - val_loss: 0.7564 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6999 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8822 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-005-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6470 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9136 - val_loss: 0.4206 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0802 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0199 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0105 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.4828e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3919e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5774e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3482e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9106e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1365e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4294e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4732e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4730 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.2941 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-005-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1218 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8994 - val_loss: 0.6627 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 3.5198 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7005 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7336 - val_loss: 4.7548 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8853 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7325 - val_loss: 3.0080 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1772 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7695 - val_loss: 1.3551 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9110 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8815 - val_loss: 0.7077 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-005-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6825 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6676 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6605 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6551 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6539 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6535 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6518 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6505 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9115 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9103 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9101 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9113 - val_loss: 0.6507 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6496 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6498 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9114 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-005-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9108 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-005-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9115 - val_loss: 0.6521 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9115 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9107 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-005-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9105 - val_loss: 0.6502 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9112 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9103 - val_loss: 0.6529 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9112 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-005-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9109 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6499 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9105 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 5/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9102 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9101 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-005-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517830982208251[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517830982208251  <  0.001
[33m[INFO] epoch 6/10[0m
[33m[INFO] loading file 1-1/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0813 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6652 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1163 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8798 - val_loss: 0.6944 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6916 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8827 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8827 - val_loss: 0.6914 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4451 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9611 - val_loss: 0.1700 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3143 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1518 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7209 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8824 - val_loss: 0.6914 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4509 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1742 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6965 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8912 - val_loss: 0.6937 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5937 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9304 - val_loss: 0.3246 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0645 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0734e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6662e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3123e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2695e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5604e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0411e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6615 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9481 - val_loss: 2.2966 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6716 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9282 - val_loss: 0.3437 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5269 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9452 - val_loss: 0.7015 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5267 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0817 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5725e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4372e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6044e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3613e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9933e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4548e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4597 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5048 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8057 - val_loss: 1.5061 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-006-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9159 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9101 - val_loss: 0.6571 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9099 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4801 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9540 - val_loss: 0.2040 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0449 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1094e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2790e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7414e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6086e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.4158e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4998 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9606 - val_loss: 0.6613 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4958 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9546 - val_loss: 0.4728 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-006-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9541 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0922 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0196 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8490e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6906e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9071e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7020e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.9045e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0239 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2943 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8945 - val_loss: 0.1494 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0629 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0240 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7299e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3624e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7582e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0319e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4000e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1685e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7413e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0074e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2109 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2427 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3059 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4006e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7041e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9515e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1443 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6426 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8659 - val_loss: 0.8110 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6776 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9101 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5278 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9452 - val_loss: 0.2450 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0525 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0161e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1216e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1200e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2647e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3201e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0940e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0171e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0530e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6226e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.8880 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.0793 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.7445 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-006-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5727 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.4132 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2159 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 9.5363e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4074e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.3060e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9185e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6504e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.5315e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4477e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2033e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.9590e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.5196e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9696e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1480 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2493 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7623 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4925 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-006-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5673 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9518 - val_loss: 1.5369 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8042 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9051 - val_loss: 0.6653 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9044 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2727 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9828 - val_loss: 0.0730 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0229 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7621e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3465e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7427e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7311 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.2418 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9236 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6936 - val_loss: 0.0282 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0241 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1198 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5363 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9543 - val_loss: 0.4748 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9545 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2044 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0515 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0161 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0052 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0028 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9544e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0630e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3612e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2302e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.2205e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.7789e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2176e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1563e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7438 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3017 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9181 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7083 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5086 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7166 - val_loss: 2.3473 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3888 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8827 - val_loss: 0.7531 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6993 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8827 - val_loss: 0.6915 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-006-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6475 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9134 - val_loss: 0.4233 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0809 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5565e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4300e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5996e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3589e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9789e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1722e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4504e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2875e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5373e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4781 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3183 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-006-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1311 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8990 - val_loss: 0.6629 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6524 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6523 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 3.5230 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6868 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7334 - val_loss: 4.7400 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8735 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7326 - val_loss: 2.9950 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1652 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7700 - val_loss: 1.3466 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9067 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8824 - val_loss: 0.7072 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-006-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6823 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6675 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6551 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9102 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9104 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6519 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6519 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6501 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9112 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9105 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9114 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6524 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9104 - val_loss: 0.6525 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6520 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9102 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9106 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9107 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6525 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9114 - val_loss: 0.6519 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-006-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-006-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9105 - val_loss: 0.6519 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9104 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-006-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6499 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6529 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9112 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-006-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9101 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 6/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9109 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-006-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517608472824097[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517608472824097  <  0.001
[33m[INFO] epoch 7/10[0m
[33m[INFO] loading file 1-1/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0809 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0199 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0105 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6770 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1131 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8803 - val_loss: 0.6937 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6915 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8826 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8828 - val_loss: 0.6915 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4449 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9614 - val_loss: 0.1676 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3142 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1417 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7199 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4502 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1748 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6956 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8910 - val_loss: 0.6946 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5937 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9300 - val_loss: 0.3261 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0644 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0558e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6579e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2923e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3517e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.7911e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.0782e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6425 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9493 - val_loss: 2.2062 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6648 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9271 - val_loss: 0.3285 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5267 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9454 - val_loss: 0.7022 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9106 - val_loss: 0.5326 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0828 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6487e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4765e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6273e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3744e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0638e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2199e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4764e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4578 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5060 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8063 - val_loss: 1.5058 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-007-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9189 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9097 - val_loss: 0.6569 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9098 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4800 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9268 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2049 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0455 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0123 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0065 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.2154e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.3404e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7724e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6272e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.5112e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4863 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9620 - val_loss: 0.6400 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4920 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9545 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-007-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9538 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0929 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9776e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7645e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9440e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7246e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0118e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0222 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2882 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8950 - val_loss: 0.1514 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0635 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7359e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3657e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7594e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0329e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4000e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1716e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7510e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0103e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2108 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2478 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3093 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3599e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6862e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9449e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1445 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6460 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8654 - val_loss: 0.8140 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6772 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5276 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9457 - val_loss: 0.2427 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0520 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0138 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9776e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1013e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1513e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2612e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3121e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.1536e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0696e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0888e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6453e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.8866 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.0866 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.7530 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-007-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5770 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.4175 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2193 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 9.4767e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3204e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.2225e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.8259e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5669e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.4370e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3524e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.1182e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.4530e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9100e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1591 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2655 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7806 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4998 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-007-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5749 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9606 - precision: 0.9016 - recall: 0.9016 - auc: 0.9513 - val_loss: 1.5540 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8086 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9055 - val_loss: 0.6652 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9050 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2726 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9826 - val_loss: 0.0749 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0234 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8407e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3915e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7653e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7403 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.2738 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9546 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6911 - val_loss: 0.0268 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0230 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1201 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5378 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9544 - val_loss: 0.4749 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9542 - val_loss: 0.4737 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2053 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9875 - val_loss: 0.0512 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0165 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.2491e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2144e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4490e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2755e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4895e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9219e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3002e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2040e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7603 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3250 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9379 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7280 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5263 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7158 - val_loss: 2.3632 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.4023 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8824 - val_loss: 0.7568 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7003 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8819 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-007-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6472 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9132 - val_loss: 0.4255 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0805 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0199 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5040e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4026e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5838e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3506e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9302e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1484e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4354e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2755e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4915e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4778 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3221 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-007-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1373 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8987 - val_loss: 0.6637 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6525 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 3.5196 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6880 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7335 - val_loss: 4.7421 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8751 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7327 - val_loss: 2.9967 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1672 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7702 - val_loss: 1.3457 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9066 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8825 - val_loss: 0.7068 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-007-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6821 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6674 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9114 - val_loss: 0.6536 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9103 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6517 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9114 - val_loss: 0.6515 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9114 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9104 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9103 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6497 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9108 - val_loss: 0.6525 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9115 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9115 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9104 - val_loss: 0.6496 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9110 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9118 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9107 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9106 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9112 - val_loss: 0.6495 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-007-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9113 - val_loss: 0.6501 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9106 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6490 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-007-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9105 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-007-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9104 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9104 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6503 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9107 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6517 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9112 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-007-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6499 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9113 - val_loss: 0.6509 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 7/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9112 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9110 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-007-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517680746078491[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517680746078491  <  0.001
[33m[INFO] epoch 8/10[0m
[33m[INFO] loading file 1-1/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0822 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6896 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1270 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8798 - val_loss: 0.6942 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6917 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8822 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8826 - val_loss: 0.6915 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4440 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9613 - val_loss: 0.1711 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3143 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9763 - val_loss: 1.1545 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7207 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8821 - val_loss: 0.6913 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4506 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9605 - val_loss: 0.1688 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6968 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8907 - val_loss: 0.6945 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5937 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9302 - val_loss: 0.3346 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0654 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0166 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0088 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.1178e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6888e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3356e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3506e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.2408e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4583e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6491 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9491 - val_loss: 2.2314 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6650 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9281 - val_loss: 0.3482 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5270 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9453 - val_loss: 0.7078 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6548 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9104 - val_loss: 0.5306 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0820 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0201 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5763e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4396e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6055e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3625e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9967e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4559e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4596 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5171 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8050 - val_loss: 1.5184 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-008-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9220 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9102 - val_loss: 0.6569 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9104 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4800 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9542 - val_loss: 0.2027 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0448 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0121 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0665e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2540e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7283e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6010e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3681e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4965 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9613 - val_loss: 0.6540 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4954 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9544 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-008-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9541 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0921 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.8383e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6840e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9035e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7001e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.8926e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0240 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2861 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8952 - val_loss: 0.1514 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0635 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7383e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3675e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7606e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0335e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4000e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1734e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7565e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0121e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2107 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2439 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3067 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.3845e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.6934e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9453e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1448 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6314 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8664 - val_loss: 0.8084 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6758 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5279 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9452 - val_loss: 0.2463 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0525 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0139 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0074 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0165e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1216e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1554e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3160e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3318e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.2489e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.2634e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3153e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8270e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.8702 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.0781 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.7436 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-008-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5693 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.4091 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2135 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 9.9535e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6279e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4371e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0066e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7219e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.5852e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.4954e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2440e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.9947e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.5502e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9934e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1530 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2595 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7778 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4987 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-008-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5730 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9515 - val_loss: 1.5507 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8068 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9054 - val_loss: 0.6653 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9049 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2739 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9824 - val_loss: 0.0768 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0238 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0076 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0041 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0012 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.9158e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4354e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7892e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7392 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.2783 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9665 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6902 - val_loss: 0.0263 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1202 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5385 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9545 - val_loss: 0.4748 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2046 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0515 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0164 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0054 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1783e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1774e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4279e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2647e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4249e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8861e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2804e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1921e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7454 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.3024 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9165 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.7044 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.5030 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7170 - val_loss: 2.3428 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3860 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8824 - val_loss: 0.7543 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6994 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8827 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-008-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6473 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9130 - val_loss: 0.4272 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0816 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6447e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4753e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6264e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3732e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0608e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2199e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4756e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2994e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6152e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0531e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4753 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.2954 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-008-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1169 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8999 - val_loss: 0.6615 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6523 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6514 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 3.5220 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6883 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7337 - val_loss: 4.7398 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8701 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7325 - val_loss: 2.9925 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1673 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7698 - val_loss: 1.3492 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9078 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8822 - val_loss: 0.7073 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-008-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6823 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9109 - val_loss: 0.6675 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6604 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6535 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6532 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9101 - val_loss: 0.6518 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6498 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6514 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9103 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6499 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9103 - val_loss: 0.6525 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6513 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6509 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9110 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9106 - val_loss: 0.6497 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9114 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9113 - val_loss: 0.6506 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9113 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9112 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9112 - val_loss: 0.6501 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9103 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9104 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9113 - val_loss: 0.6518 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-008-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6500 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6530 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9105 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6521 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-008-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6519 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9115 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9117 - val_loss: 0.6524 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6508 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-008-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6503 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6513 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9114 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-008-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9114 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6499 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9109 - val_loss: 0.6527 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 8/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9111 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-008-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517982133865357[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517982133865357  <  0.001
[33m[INFO] epoch 9/10[0m
[33m[INFO] loading file 1-1/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0827 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6656 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1088 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8804 - val_loss: 0.6939 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6915 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8826 - val_loss: 0.6913 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8825 - val_loss: 0.6916 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4438 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9612 - val_loss: 0.1689 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3144 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9761 - val_loss: 1.1557 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7204 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8823 - val_loss: 0.6914 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4496 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1743 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6955 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8917 - val_loss: 0.6930 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5939 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9303 - val_loss: 0.3303 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0648 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0164 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0042 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0709e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6650e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3220e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3160e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.9067e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2318e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6575 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9485 - val_loss: 2.2634 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6704 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3436 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5270 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9450 - val_loss: 0.7007 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6547 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9103 - val_loss: 0.5358 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0838 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0205 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0109 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0052 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0030 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.7388e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5230e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6545e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3875e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1471e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.2676e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5020e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4555 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5108 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8055 - val_loss: 1.5115 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-009-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9190 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8561 - precision: 0.6401 - recall: 0.6401 - auc: 0.9102 - val_loss: 0.6567 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4802 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9543 - val_loss: 0.2011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0445 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.0165e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2251e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7128e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.5922e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.3324e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4907 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9615 - val_loss: 0.6454 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4926 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9547 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-009-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0918 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0035 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.7763e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6485e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.8856e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6891e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.8330e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0262 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2945 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8944 - val_loss: 0.1490 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0628 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0240 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0131 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0064 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0037 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7180e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3558e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7546e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.0299e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.3881e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1623e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6570e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.7223e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1260e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0014e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2112 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2423 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3060 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0016 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0014 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.4061e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.7065e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9535e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1441 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6334 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8667 - val_loss: 0.8077 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6761 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9104 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5278 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9451 - val_loss: 0.2471 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0535 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0142 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0076 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.1612e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1967e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.2050e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3815e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3223e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.4861e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9899e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4106e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0126e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.8470 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 10.0218 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.6864 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-009-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5126 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.3534 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.1816 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 1.1360e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6577e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.2596e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.7683e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.4371e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.2745e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.1152e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.8370e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.5192e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.9989e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3391e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1375 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2368 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7522 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4897 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-009-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5622 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9524 - val_loss: 1.5111 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7952 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9055 - val_loss: 0.6653 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9045 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2734 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9829 - val_loss: 0.0721 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0229 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0075 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.7979e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3673e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7534e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7297 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.2309 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.9058 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6950 - val_loss: 0.0289 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0247 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1197 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5346 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9546 - val_loss: 0.4748 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9545 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2048 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9876 - val_loss: 0.0523 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0163 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0341e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1035e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3848e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2421e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.2924e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.8146e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.2397e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1682e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7239 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.2708 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.8852 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.6751 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4750 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7194 - val_loss: 2.3129 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3648 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8825 - val_loss: 0.7469 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6982 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8828 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-009-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6474 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8614 - precision: 0.6534 - recall: 0.6534 - auc: 0.9130 - val_loss: 0.4316 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0818 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0107 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6272e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4562e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.6145e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3660e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.0141e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1842e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.4564e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2875e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.5285e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9339e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4764 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3050 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-009-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1245 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8994 - val_loss: 0.6624 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9102 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9111 - val_loss: 3.5156 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6718 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7334 - val_loss: 4.7229 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8531 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7323 - val_loss: 2.9741 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1455 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7712 - val_loss: 1.3304 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9007 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8834 - val_loss: 0.7062 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-009-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6819 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6673 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6603 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9109 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9109 - val_loss: 0.6526 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9102 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9102 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9107 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9108 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9113 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9103 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9104 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9107 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9106 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9114 - val_loss: 0.6510 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9107 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9115 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9107 - val_loss: 0.6524 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6513 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9112 - val_loss: 0.6521 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8579 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9109 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9108 - val_loss: 0.6495 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9106 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9108 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6513 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9113 - val_loss: 0.6510 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6506 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6524 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9104 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9115 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9118 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9106 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9108 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9111 - val_loss: 0.6526 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9108 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9109 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9106 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-009-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9106 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9107 - val_loss: 0.6510 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6501 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9106 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6527 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9109 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-009-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6520 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9108 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9111 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9111 - val_loss: 0.6522 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9102 - val_loss: 0.6506 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-009-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9112 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6511 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9110 - val_loss: 0.6498 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9106 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9103 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6502 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9107 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9114 - val_loss: 0.6512 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9109 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9113 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-009-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6498 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6499 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9111 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 9/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9113 - val_loss: 0.6509 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9104 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9104 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-009-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517679664611816[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517679664611816  <  0.001
[33m[INFO] epoch 10/10[0m
[33m[INFO] loading file 1-1/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0815 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0200 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0106 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0202 - tp: 79766.0000 - fp: 234.0000 - tn: 319766.0000 - fn: 234.0000 - accuracy: 0.9988 - precision: 0.9971 - recall: 0.9971 - auc: 0.9982 - val_loss: 2.6704 - val_tp: 10606.0000 - val_fp: 9394.0000 - val_tn: 70606.0000 - val_fn: 9394.0000 - val_accuracy: 0.8121 - val_precision: 0.5303 - val_recall: 0.5303 - val_auc: 0.7064
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1118 - tp: 42447.0000 - fp: 37553.0000 - tn: 282447.0000 - fn: 37553.0000 - accuracy: 0.8122 - precision: 0.5306 - recall: 0.5306 - auc: 0.8804 - val_loss: 0.6938 - val_tp: 10626.0000 - val_fp: 9374.0000 - val_tn: 70626.0000 - val_fn: 9374.0000 - val_accuracy: 0.8125 - val_precision: 0.5313 - val_recall: 0.5313 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6916 - tp: 42438.0000 - fp: 37562.0000 - tn: 282438.0000 - fn: 37562.0000 - accuracy: 0.8122 - precision: 0.5305 - recall: 0.5305 - auc: 0.8822 - val_loss: 0.6914 - val_tp: 10603.0000 - val_fp: 9397.0000 - val_tn: 70603.0000 - val_fn: 9397.0000 - val_accuracy: 0.8121 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-0-1
[33m[INFO] loading file 2-2/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_113021_98.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6913 - tp: 42435.0000 - fp: 37565.0000 - tn: 282435.0000 - fn: 37565.0000 - accuracy: 0.8122 - precision: 0.5304 - recall: 0.5304 - auc: 0.8824 - val_loss: 0.6916 - val_tp: 10589.0000 - val_fp: 9411.0000 - val_tn: 70589.0000 - val_fn: 9411.0000 - val_accuracy: 0.8118 - val_precision: 0.5294 - val_recall: 0.5294 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4434 - tp: 67619.0000 - fp: 12381.0000 - tn: 307619.0000 - fn: 12381.0000 - accuracy: 0.9381 - precision: 0.8452 - recall: 0.8452 - auc: 0.9615 - val_loss: 0.1683 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.3141 - tp: 72432.0000 - fp: 7568.0000 - tn: 312432.0000 - fn: 7568.0000 - accuracy: 0.9622 - precision: 0.9054 - recall: 0.9054 - auc: 0.9765 - val_loss: 1.1637 - val_tp: 10593.0000 - val_fp: 9407.0000 - val_tn: 70593.0000 - val_fn: 9407.0000 - val_accuracy: 0.8119 - val_precision: 0.5296 - val_recall: 0.5296 - val_auc: 0.8824
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.7233 - tp: 42321.0000 - fp: 37679.0000 - tn: 282321.0000 - fn: 37679.0000 - accuracy: 0.8116 - precision: 0.5290 - recall: 0.5290 - auc: 0.8816 - val_loss: 0.6914 - val_tp: 10602.0000 - val_fp: 9398.0000 - val_tn: 70602.0000 - val_fn: 9398.0000 - val_accuracy: 0.8120 - val_precision: 0.5301 - val_recall: 0.5301 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4506 - tp: 67360.0000 - fp: 12640.0000 - tn: 307360.0000 - fn: 12640.0000 - accuracy: 0.9368 - precision: 0.8420 - recall: 0.8420 - auc: 0.9604 - val_loss: 0.1721 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-1-2
[33m[INFO] loading file 3-3/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6964 - tp: 45236.0000 - fp: 34764.0000 - tn: 285236.0000 - fn: 34764.0000 - accuracy: 0.8262 - precision: 0.5655 - recall: 0.5655 - auc: 0.8913 - val_loss: 0.6936 - val_tp: 10571.0000 - val_fp: 9429.0000 - val_tn: 70571.0000 - val_fn: 9429.0000 - val_accuracy: 0.8114 - val_precision: 0.5286 - val_recall: 0.5286 - val_auc: 0.8821
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5940 - tp: 57751.0000 - fp: 22249.0000 - tn: 297751.0000 - fn: 22249.0000 - accuracy: 0.8888 - precision: 0.7219 - recall: 0.7219 - auc: 0.9304 - val_loss: 0.3214 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0637 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0163 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0086 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0041 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0024 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-2-3
[33m[INFO] loading file 4-4/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0792e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6162e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2835e-04 - tp: 79999.0000 - fp: 1.0000 - tn: 319999.0000 - fn: 1.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2886e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.8557e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1961e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 71528.0000 - fp: 8472.0000 - tn: 311528.0000 - fn: 8472.0000 - accuracy: 0.9576 - precision: 0.8941 - recall: 0.8941 - auc: 0.9488 - val_loss: 2.2497 - val_tp: 7806.0000 - val_fp: 12194.0000 - val_tn: 67806.0000 - val_fn: 12194.0000 - val_accuracy: 0.7561 - val_precision: 0.3903 - val_recall: 0.3903 - val_auc: 0.8476
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6681 - tp: 56887.0000 - fp: 23113.0000 - tn: 296887.0000 - fn: 23113.0000 - accuracy: 0.8844 - precision: 0.7111 - recall: 0.7111 - auc: 0.9278 - val_loss: 0.3433 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-3-4
[33m[INFO] loading file 5-5/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5271 - tp: 62445.0000 - fp: 17555.0000 - tn: 302445.0000 - fn: 17555.0000 - accuracy: 0.9122 - precision: 0.7806 - recall: 0.7806 - auc: 0.9448 - val_loss: 0.6987 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6546 - tp: 51316.0000 - fp: 28684.0000 - tn: 291316.0000 - fn: 28684.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.9102 - val_loss: 0.5334 - val_tp: 17052.0000 - val_fp: 2948.0000 - val_tn: 77052.0000 - val_fn: 2948.0000 - val_accuracy: 0.9410 - val_precision: 0.8526 - val_recall: 0.8526 - val_auc: 0.9632
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0829 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0203 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0108 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0051 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0030 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-4-5
[33m[INFO] loading file 6-6/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.7801e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.4848e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5921e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3327e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.8054e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.0769e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3867e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.4664 - val_tp: 15632.0000 - val_fp: 4368.0000 - val_tn: 75632.0000 - val_fn: 4368.0000 - val_accuracy: 0.9126 - val_precision: 0.7816 - val_recall: 0.7816 - val_auc: 0.8635
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5285 - tp: 51195.0000 - fp: 28805.0000 - tn: 291195.0000 - fn: 28805.0000 - accuracy: 0.8560 - precision: 0.6399 - recall: 0.6399 - auc: 0.8045 - val_loss: 1.5274 - val_tp: 12768.0000 - val_fp: 7232.0000 - val_tn: 72768.0000 - val_fn: 7232.0000 - val_accuracy: 0.8554 - val_precision: 0.6384 - val_recall: 0.6384 - val_auc: 0.9096
[INFO] saving weights to checkpoints/dnn-epoch-010-files-5-6
[33m[INFO] loading file 7-7/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9279 - tp: 51210.0000 - fp: 28790.0000 - tn: 291210.0000 - fn: 28790.0000 - accuracy: 0.8560 - precision: 0.6401 - recall: 0.6401 - auc: 0.9101 - val_loss: 0.6571 - val_tp: 12803.0000 - val_fp: 7197.0000 - val_tn: 72803.0000 - val_fn: 7197.0000 - val_accuracy: 0.8561 - val_precision: 0.6402 - val_recall: 0.6402 - val_auc: 0.9100
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6528 - tp: 51338.0000 - fp: 28662.0000 - tn: 291338.0000 - fn: 28662.0000 - accuracy: 0.8567 - precision: 0.6417 - recall: 0.6417 - auc: 0.9100 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4800 - tp: 65370.0000 - fp: 14630.0000 - tn: 305370.0000 - fn: 14630.0000 - accuracy: 0.9269 - precision: 0.8171 - recall: 0.8171 - auc: 0.9544 - val_loss: 0.1971 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0442 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0120 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0064 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-6-7
[33m[INFO] loading file 8-8/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0018 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.1582e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.2911e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.7033e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.5629e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.0582e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4864 - tp: 73166.0000 - fp: 6834.0000 - tn: 313166.0000 - fn: 6834.0000 - accuracy: 0.9658 - precision: 0.9146 - recall: 0.9146 - auc: 0.9621 - val_loss: 0.6425 - val_tp: 16368.0000 - val_fp: 3632.0000 - val_tn: 76368.0000 - val_fn: 3632.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4920 - tp: 65505.0000 - fp: 14495.0000 - tn: 305505.0000 - fn: 14495.0000 - accuracy: 0.9275 - precision: 0.8188 - recall: 0.8188 - auc: 0.9547 - val_loss: 0.4727 - val_tp: 16383.0000 - val_fp: 3617.0000 - val_tn: 76383.0000 - val_fn: 3617.0000 - val_accuracy: 0.9277 - val_precision: 0.8191 - val_recall: 0.8191 - val_auc: 0.9548
[INFO] saving weights to checkpoints/dnn-epoch-010-files-7-8
[33m[INFO] loading file 9-9/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-28_164554_99.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4771 - tp: 65300.0000 - fp: 14700.0000 - tn: 305300.0000 - fn: 14700.0000 - accuracy: 0.9265 - precision: 0.8163 - recall: 0.8163 - auc: 0.9539 - val_loss: 0.4802 - val_tp: 16283.0000 - val_fp: 3717.0000 - val_tn: 76283.0000 - val_fn: 3717.0000 - val_accuracy: 0.9257 - val_precision: 0.8141 - val_recall: 0.8141 - val_auc: 0.9535
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0922 - tp: 78936.0000 - fp: 1064.0000 - tn: 318936.0000 - fn: 1064.0000 - accuracy: 0.9947 - precision: 0.9867 - recall: 0.9867 - auc: 0.9967 - val_loss: 0.0195 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0087 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0036 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0020 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.8231e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.9750e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-8-9
[33m[INFO] loading file 10-10/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7183e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 8.7734e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0072 - tp: 79936.0000 - fp: 64.0000 - tn: 319936.0000 - fn: 64.0000 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9992 - auc: 0.9995 - val_loss: 3.0163 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.7763
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2768 - tp: 56672.0000 - fp: 23328.0000 - tn: 296672.0000 - fn: 23328.0000 - accuracy: 0.8834 - precision: 0.7084 - recall: 0.7084 - auc: 0.8959 - val_loss: 0.1553 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0642 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0241 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0132 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0065 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-9-10
[33m[INFO] loading file 11-11/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0038 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.6942e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2928e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.6986e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.9512e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.1855e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.0423e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.5855e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-10-11
[33m[INFO] loading file 12-12/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_134830_103.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.3148e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.8876e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8634e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.2195 - val_tp: 16689.0000 - val_fp: 3311.0000 - val_tn: 76689.0000 - val_fn: 3311.0000 - val_accuracy: 0.9338 - val_precision: 0.8345 - val_recall: 0.8345 - val_auc: 0.8965
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.2752 - tp: 51328.0000 - fp: 28672.0000 - tn: 291328.0000 - fn: 28672.0000 - accuracy: 0.8566 - precision: 0.6416 - recall: 0.6416 - auc: 0.7760 - val_loss: 1.3262 - val_tp: 15792.0000 - val_fp: 4208.0000 - val_tn: 75792.0000 - val_fn: 4208.0000 - val_accuracy: 0.9158 - val_precision: 0.7896 - val_recall: 0.7896 - val_auc: 0.8685
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0019 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0018 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0017 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-11-12
[33m[INFO] loading file 13-13/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0013 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 9.9967e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.1449e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.5671e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.8859e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 2.1490 - val_tp: 15075.0000 - val_fp: 4925.0000 - val_tn: 75075.0000 - val_fn: 4925.0000 - val_accuracy: 0.9015 - val_precision: 0.7538 - val_recall: 0.7538 - val_auc: 0.8461
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.6544 - tp: 51313.0000 - fp: 28687.0000 - tn: 291313.0000 - fn: 28687.0000 - accuracy: 0.8566 - precision: 0.6414 - recall: 0.6414 - auc: 0.8650 - val_loss: 0.8199 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6784 - tp: 51356.0000 - fp: 28644.0000 - tn: 291356.0000 - fn: 28644.0000 - accuracy: 0.8568 - precision: 0.6420 - recall: 0.6420 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-12-13
[33m[INFO] loading file 14-14/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5277 - tp: 62543.0000 - fp: 17457.0000 - tn: 302543.0000 - fn: 17457.0000 - accuracy: 0.9127 - precision: 0.7818 - recall: 0.7818 - auc: 0.9453 - val_loss: 0.2491 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0537 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0142 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0076 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0037 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0021 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.2414e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.1883e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-13-14
[33m[INFO] loading file 15-15/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (500000, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 4.1931e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3374e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 100000-200000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3326e-04 - tp: 79998.0000 - fp: 2.0000 - tn: 319998.0000 - fn: 2.0000 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 7.7006e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 200000-300000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 6.0630e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3868e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 300000-400000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9707e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 10.5249 - val_tp: 11586.0000 - val_fp: 8414.0000 - val_tn: 71586.0000 - val_fn: 8414.0000 - val_accuracy: 0.8317 - val_precision: 0.5793 - val_recall: 0.5793 - val_auc: 0.7371
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[INFO] processing batch 400000-500000/500000
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 9.6923 - tp: 42561.0000 - fp: 37439.0000 - tn: 282561.0000 - fn: 37439.0000 - accuracy: 0.8128 - precision: 0.5320 - recall: 0.5320 - auc: 0.7075 - val_loss: 8.3573 - val_tp: 10627.0000 - val_fp: 9373.0000 - val_tn: 70627.0000 - val_fn: 9373.0000 - val_accuracy: 0.8125 - val_precision: 0.5314 - val_recall: 0.5314 - val_auc: 0.7071
[INFO] saving weights to checkpoints/dnn-epoch-010-files-14-15
[33m[INFO] loading file 16-16/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-29_190411_104.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (439690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] processing batch 0-100000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.1801 - tp: 42492.0000 - fp: 37508.0000 - tn: 282492.0000 - fn: 37508.0000 - accuracy: 0.8125 - precision: 0.5311 - recall: 0.5311 - auc: 0.7070 - val_loss: 6.0185 - val_tp: 10618.0000 - val_fp: 9382.0000 - val_tn: 70618.0000 - val_fn: 9382.0000 - val_accuracy: 0.8124 - val_precision: 0.5309 - val_recall: 0.5309 - val_auc: 0.7068
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 100000-200000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.9883 - tp: 58381.0000 - fp: 21619.0000 - tn: 298381.0000 - fn: 21619.0000 - accuracy: 0.8919 - precision: 0.7298 - recall: 0.7298 - auc: 0.8311 - val_loss: 1.7296e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 200000-300000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.4855e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.3529e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 300000-400000/439690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3053e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2731e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-15-16
[INFO] processing batch 400000-500000/439690
[33m[INFO] loading file 17-17/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_001940_105.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.2571e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2278e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1332e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.0299e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.6737e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 6.8185e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1449 - tp: 68607.0000 - fp: 11393.0000 - tn: 308607.0000 - fn: 11393.0000 - accuracy: 0.9430 - precision: 0.8576 - recall: 0.8576 - auc: 0.9110 - val_loss: 2.2457 - val_tp: 16369.0000 - val_fp: 3631.0000 - val_tn: 76369.0000 - val_fn: 3631.0000 - val_accuracy: 0.9274 - val_precision: 0.8184 - val_recall: 0.8184 - val_auc: 0.8865
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7624 - tp: 65526.0000 - fp: 14474.0000 - tn: 305526.0000 - fn: 14474.0000 - accuracy: 0.9276 - precision: 0.8191 - recall: 0.8191 - auc: 0.8869 - val_loss: 0.4929 - val_tp: 18648.0000 - val_fp: 1352.0000 - val_tn: 78648.0000 - val_fn: 1352.0000 - val_accuracy: 0.9730 - val_precision: 0.9324 - val_recall: 0.9324 - val_auc: 0.9577
[INFO] saving weights to checkpoints/dnn-epoch-010-files-16-17
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 18-18/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_053515_106.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5659 - tp: 72130.0000 - fp: 7870.0000 - tn: 312130.0000 - fn: 7870.0000 - accuracy: 0.9607 - precision: 0.9016 - recall: 0.9016 - auc: 0.9522 - val_loss: 1.5270 - val_tp: 12369.0000 - val_fp: 7631.0000 - val_tn: 72369.0000 - val_fn: 7631.0000 - val_accuracy: 0.8474 - val_precision: 0.6184 - val_recall: 0.6184 - val_auc: 0.9046
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.8009 - tp: 49699.0000 - fp: 30301.0000 - tn: 289699.0000 - fn: 30301.0000 - accuracy: 0.8485 - precision: 0.6212 - recall: 0.6212 - auc: 0.9052 - val_loss: 0.6654 - val_tp: 12357.0000 - val_fp: 7643.0000 - val_tn: 72357.0000 - val_fn: 7643.0000 - val_accuracy: 0.8471 - val_precision: 0.6179 - val_recall: 0.6179 - val_auc: 0.9045
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6645 - tp: 49541.0000 - fp: 30459.0000 - tn: 289541.0000 - fn: 30459.0000 - accuracy: 0.8477 - precision: 0.6193 - recall: 0.6193 - auc: 0.9051 - val_loss: 0.6642 - val_tp: 12397.0000 - val_fp: 7603.0000 - val_tn: 72397.0000 - val_fn: 7603.0000 - val_accuracy: 0.8479 - val_precision: 0.6198 - val_recall: 0.6198 - val_auc: 0.9050
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2724 - tp: 74509.0000 - fp: 5491.0000 - tn: 314509.0000 - fn: 5491.0000 - accuracy: 0.9725 - precision: 0.9314 - recall: 0.9314 - auc: 0.9831 - val_loss: 0.0713 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0227 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0074 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-17-18
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 19-19/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0040 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0020 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0011 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 5.8300e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.3685e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.7200e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.7178 - tp: 69321.0000 - fp: 10679.0000 - tn: 309321.0000 - fn: 10679.0000 - accuracy: 0.9466 - precision: 0.8665 - recall: 0.8665 - auc: 0.9166 - val_loss: 6.1840 - val_tp: 7882.0000 - val_fp: 12118.0000 - val_tn: 67882.0000 - val_fn: 12118.0000 - val_accuracy: 0.7576 - val_precision: 0.3941 - val_recall: 0.3941 - val_auc: 0.6213
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8606 - tp: 31237.0000 - fp: 48763.0000 - tn: 271237.0000 - fn: 48763.0000 - accuracy: 0.7562 - precision: 0.3905 - recall: 0.3905 - auc: 0.6984 - val_loss: 0.0311 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-18-19
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 20-20/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_105053_107.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539690, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0263 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.1194 - val_tp: 19491.0000 - val_fp: 509.0000 - val_tn: 79491.0000 - val_fn: 509.0000 - val_accuracy: 0.9898 - val_precision: 0.9746 - val_recall: 0.9746 - val_auc: 0.9936
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 100000-200000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.5329 - tp: 65427.0000 - fp: 14573.0000 - tn: 305427.0000 - fn: 14573.0000 - accuracy: 0.9271 - precision: 0.8178 - recall: 0.8178 - auc: 0.9542 - val_loss: 0.4749 - val_tp: 16357.0000 - val_fp: 3643.0000 - val_tn: 76357.0000 - val_fn: 3643.0000 - val_accuracy: 0.9271 - val_precision: 0.8178 - val_recall: 0.8178 - val_auc: 0.9545
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 200000-300000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4762 - tp: 65351.0000 - fp: 14649.0000 - tn: 305351.0000 - fn: 14649.0000 - accuracy: 0.9268 - precision: 0.8169 - recall: 0.8169 - auc: 0.9540 - val_loss: 0.4736 - val_tp: 16371.0000 - val_fp: 3629.0000 - val_tn: 76371.0000 - val_fn: 3629.0000 - val_accuracy: 0.9274 - val_precision: 0.8185 - val_recall: 0.8185 - val_auc: 0.9546
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 300000-400000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.2047 - tp: 76024.0000 - fp: 3976.0000 - tn: 316024.0000 - fn: 3976.0000 - accuracy: 0.9801 - precision: 0.9503 - recall: 0.9503 - auc: 0.9875 - val_loss: 0.0517 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 400000-500000/539690
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0162 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0053 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-19-20
[INFO] processing batch 500000-600000/539690
[33m[INFO] loading file 21-21/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539688, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 100000-200000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.1281e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.1524e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 200000-300000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3990e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2242e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 300000-400000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.0947e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6835e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 400000-500000/539688
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1558e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.1206e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-20-21
[INFO] processing batch 500000-600000/539688
[33m[INFO] loading file 22-22/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.7395 - tp: 55006.0000 - fp: 24994.0000 - tn: 295006.0000 - fn: 24994.0000 - accuracy: 0.8750 - precision: 0.6876 - recall: 0.6876 - auc: 0.8047 - val_loss: 7.2934 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.7066
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.9050 - tp: 42398.0000 - fp: 37602.0000 - tn: 282398.0000 - fn: 37602.0000 - accuracy: 0.8120 - precision: 0.5300 - recall: 0.5300 - auc: 0.7062 - val_loss: 4.6938 - val_tp: 10527.0000 - val_fp: 9473.0000 - val_tn: 70527.0000 - val_fn: 9473.0000 - val_accuracy: 0.8105 - val_precision: 0.5264 - val_recall: 0.5264 - val_auc: 0.7040
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.4918 - tp: 42369.0000 - fp: 37631.0000 - tn: 282369.0000 - fn: 37631.0000 - accuracy: 0.8118 - precision: 0.5296 - recall: 0.5296 - auc: 0.7181 - val_loss: 2.3297 - val_tp: 10623.0000 - val_fp: 9377.0000 - val_tn: 70623.0000 - val_fn: 9377.0000 - val_accuracy: 0.8125 - val_precision: 0.5311 - val_recall: 0.5311 - val_auc: 0.8828
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.3769 - tp: 42452.0000 - fp: 37548.0000 - tn: 282452.0000 - fn: 37548.0000 - accuracy: 0.8123 - precision: 0.5307 - recall: 0.5307 - auc: 0.8826 - val_loss: 0.7510 - val_tp: 10601.0000 - val_fp: 9399.0000 - val_tn: 70601.0000 - val_fn: 9399.0000 - val_accuracy: 0.8120 - val_precision: 0.5300 - val_recall: 0.5300 - val_auc: 0.8825
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6990 - tp: 42382.0000 - fp: 37618.0000 - tn: 282382.0000 - fn: 37618.0000 - accuracy: 0.8119 - precision: 0.5298 - recall: 0.5298 - auc: 0.8825 - val_loss: 0.6913 - val_tp: 10612.0000 - val_fp: 9388.0000 - val_tn: 70612.0000 - val_fn: 9388.0000 - val_accuracy: 0.8122 - val_precision: 0.5306 - val_recall: 0.5306 - val_auc: 0.8827
[INFO] saving weights to checkpoints/dnn-epoch-010-files-21-22
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 23-23/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-30_212042_109.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6470 - tp: 52270.0000 - fp: 27730.0000 - tn: 292270.0000 - fn: 27730.0000 - accuracy: 0.8613 - precision: 0.6534 - recall: 0.6534 - auc: 0.9137 - val_loss: 0.4125 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0793 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0198 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0105 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.0029 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 0.0015 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 8.5570e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 4.3716e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-22-23
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 24-24/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.5263e-04 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2993e-04 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.6097e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.9696e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.3269e-05 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 1.2159e-05 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 7.1290e-06 - tp: 80000.0000 - fp: 0.0000e+00 - tn: 320000.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - val_loss: 3.6955e-06 - val_tp: 20000.0000 - val_fp: 0.0000e+00 - val_tn: 80000.0000 - val_fn: 0.0000e+00 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 1.0000
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.4781 - tp: 75698.0000 - fp: 4302.0000 - tn: 315698.0000 - fn: 4302.0000 - accuracy: 0.9785 - precision: 0.9462 - recall: 0.9462 - auc: 0.9664 - val_loss: 2.3240 - val_tp: 12912.0000 - val_fp: 7088.0000 - val_tn: 72912.0000 - val_fn: 7088.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7785
[INFO] saving weights to checkpoints/dnn-epoch-010-files-23-24
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 25-25/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 1.1423 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.8981 - val_loss: 0.6649 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6527 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9104 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51503.0000 - fp: 28497.0000 - tn: 291503.0000 - fn: 28497.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9108 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-24-25
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 26-26/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (539687, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51523.0000 - fp: 28477.0000 - tn: 291523.0000 - fn: 28477.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9114 - val_loss: 3.5165 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.8310
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 100000-200000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 5.6757 - tp: 51579.0000 - fp: 28421.0000 - tn: 291579.0000 - fn: 28421.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.7335 - val_loss: 4.7296 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.7324
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 200000-300000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 3.8589 - tp: 51462.0000 - fp: 28538.0000 - tn: 291462.0000 - fn: 28538.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.7325 - val_loss: 2.9776 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.7342
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 300000-400000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 2.1499 - tp: 51506.0000 - fp: 28494.0000 - tn: 291506.0000 - fn: 28494.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.7710 - val_loss: 1.3328 - val_tp: 12936.0000 - val_fp: 7064.0000 - val_tn: 72936.0000 - val_fn: 7064.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.8234
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 400000-500000/539687
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.9016 - tp: 51474.0000 - fp: 28526.0000 - tn: 291474.0000 - fn: 28526.0000 - accuracy: 0.8574 - precision: 0.6434 - recall: 0.6434 - auc: 0.8831 - val_loss: 0.7064 - val_tp: 12945.0000 - val_fp: 7055.0000 - val_tn: 72945.0000 - val_fn: 7055.0000 - val_accuracy: 0.8589 - val_precision: 0.6472 - val_recall: 0.6472 - val_auc: 0.9118
[INFO] saving weights to checkpoints/dnn-epoch-010-files-25-26
[INFO] processing batch 500000-600000/539687
[33m[INFO] loading file 27-27/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_023431_110.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (479817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6820 - tp: 51419.0000 - fp: 28581.0000 - tn: 291419.0000 - fn: 28581.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9104 - val_loss: 0.6674 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 100000-200000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6603 - tp: 51485.0000 - fp: 28515.0000 - tn: 291485.0000 - fn: 28515.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6550 - val_tp: 12918.0000 - val_fp: 7082.0000 - val_tn: 72918.0000 - val_fn: 7082.0000 - val_accuracy: 0.8584 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 200000-300000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6538 - tp: 51583.0000 - fp: 28417.0000 - tn: 291583.0000 - fn: 28417.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9107 - val_loss: 0.6534 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 300000-400000/479817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6531 - tp: 51396.0000 - fp: 28604.0000 - tn: 291396.0000 - fn: 28604.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9105 - val_loss: 0.6529 - val_tp: 12851.0000 - val_fp: 7149.0000 - val_tn: 72851.0000 - val_fn: 7149.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-26-27
[INFO] processing batch 400000-500000/479817
[33m[INFO] loading file 28-28/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9105 - val_loss: 0.6516 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6522 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9101 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51458.0000 - fp: 28542.0000 - tn: 291458.0000 - fn: 28542.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-27-28
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 29-29/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51460.0000 - fp: 28540.0000 - tn: 291460.0000 - fn: 28540.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51527.0000 - fp: 28473.0000 - tn: 291527.0000 - fn: 28473.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9108 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-28-29
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 30-30/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9106 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6517 - tp: 51450.0000 - fp: 28550.0000 - tn: 291450.0000 - fn: 28550.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9102 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9109 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9112 - val_loss: 0.6514 - val_tp: 12870.0000 - val_fp: 7130.0000 - val_tn: 72870.0000 - val_fn: 7130.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-29-30
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 31-31/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6499 - val_tp: 12921.0000 - val_fp: 7079.0000 - val_tn: 72921.0000 - val_fn: 7079.0000 - val_accuracy: 0.8584 - val_precision: 0.6460 - val_recall: 0.6460 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51524.0000 - fp: 28476.0000 - tn: 291524.0000 - fn: 28476.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9113 - val_loss: 0.6504 - val_tp: 12902.0000 - val_fp: 7098.0000 - val_tn: 72902.0000 - val_fn: 7098.0000 - val_accuracy: 0.8580 - val_precision: 0.6451 - val_recall: 0.6451 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51428.0000 - fp: 28572.0000 - tn: 291428.0000 - fn: 28572.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9105 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51479.0000 - fp: 28521.0000 - tn: 291479.0000 - fn: 28521.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9111 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12893.0000 - val_fp: 7107.0000 - val_tn: 72893.0000 - val_fn: 7107.0000 - val_accuracy: 0.8579 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-30-31
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 32-32/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51484.0000 - fp: 28516.0000 - tn: 291484.0000 - fn: 28516.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9109 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51531.0000 - fp: 28469.0000 - tn: 291531.0000 - fn: 28469.0000 - accuracy: 0.8577 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51576.0000 - fp: 28424.0000 - tn: 291576.0000 - fn: 28424.0000 - accuracy: 0.8579 - precision: 0.6447 - recall: 0.6447 - auc: 0.9112 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51489.0000 - fp: 28511.0000 - tn: 291489.0000 - fn: 28511.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51449.0000 - fp: 28551.0000 - tn: 291449.0000 - fn: 28551.0000 - accuracy: 0.8572 - precision: 0.6431 - recall: 0.6431 - auc: 0.9108 - val_loss: 0.6515 - val_tp: 12867.0000 - val_fp: 7133.0000 - val_tn: 72867.0000 - val_fn: 7133.0000 - val_accuracy: 0.8573 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-31-32
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 33-33/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51508.0000 - fp: 28492.0000 - tn: 291508.0000 - fn: 28492.0000 - accuracy: 0.8575 - precision: 0.6439 - recall: 0.6439 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6516 - val_tp: 12864.0000 - val_fp: 7136.0000 - val_tn: 72864.0000 - val_fn: 7136.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51404.0000 - fp: 28596.0000 - tn: 291404.0000 - fn: 28596.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9109 - val_loss: 0.6516 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51552.0000 - fp: 28448.0000 - tn: 291552.0000 - fn: 28448.0000 - accuracy: 0.8578 - precision: 0.6444 - recall: 0.6444 - auc: 0.9107 - val_loss: 0.6509 - val_tp: 12886.0000 - val_fp: 7114.0000 - val_tn: 72886.0000 - val_fn: 7114.0000 - val_accuracy: 0.8577 - val_precision: 0.6443 - val_recall: 0.6443 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51594.0000 - fp: 28406.0000 - tn: 291594.0000 - fn: 28406.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9110 - val_loss: 0.6496 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-32-33
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 34-34/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9112 - val_loss: 0.6522 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51470.0000 - fp: 28530.0000 - tn: 291470.0000 - fn: 28530.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9110 - val_loss: 0.6516 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51588.0000 - fp: 28412.0000 - tn: 291588.0000 - fn: 28412.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51408.0000 - fp: 28592.0000 - tn: 291408.0000 - fn: 28592.0000 - accuracy: 0.8570 - precision: 0.6426 - recall: 0.6426 - auc: 0.9106 - val_loss: 0.6525 - val_tp: 12834.0000 - val_fp: 7166.0000 - val_tn: 72834.0000 - val_fn: 7166.0000 - val_accuracy: 0.8567 - val_precision: 0.6417 - val_recall: 0.6417 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9107 - val_loss: 0.6512 - val_tp: 12877.0000 - val_fp: 7123.0000 - val_tn: 72877.0000 - val_fn: 7123.0000 - val_accuracy: 0.8575 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-33-34
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 35-35/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51520.0000 - fp: 28480.0000 - tn: 291520.0000 - fn: 28480.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9108 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9108 - val_loss: 0.6512 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6508 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51521.0000 - fp: 28479.0000 - tn: 291521.0000 - fn: 28479.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51570.0000 - fp: 28430.0000 - tn: 291570.0000 - fn: 28430.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6513 - val_tp: 12872.0000 - val_fp: 7128.0000 - val_tn: 72872.0000 - val_fn: 7128.0000 - val_accuracy: 0.8574 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-34-35
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 36-36/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12874.0000 - val_fp: 7126.0000 - val_tn: 72874.0000 - val_fn: 7126.0000 - val_accuracy: 0.8575 - val_precision: 0.6437 - val_recall: 0.6437 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6502 - tp: 51644.0000 - fp: 28356.0000 - tn: 291644.0000 - fn: 28356.0000 - accuracy: 0.8582 - precision: 0.6456 - recall: 0.6456 - auc: 0.9114 - val_loss: 0.6506 - val_tp: 12895.0000 - val_fp: 7105.0000 - val_tn: 72895.0000 - val_fn: 7105.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6520 - tp: 51397.0000 - fp: 28603.0000 - tn: 291397.0000 - fn: 28603.0000 - accuracy: 0.8570 - precision: 0.6425 - recall: 0.6425 - auc: 0.9111 - val_loss: 0.6500 - val_tp: 12933.0000 - val_fp: 7067.0000 - val_tn: 72933.0000 - val_fn: 7067.0000 - val_accuracy: 0.8587 - val_precision: 0.6467 - val_recall: 0.6467 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51415.0000 - fp: 28585.0000 - tn: 291415.0000 - fn: 28585.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12878.0000 - val_fp: 7122.0000 - val_tn: 72878.0000 - val_fn: 7122.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51498.0000 - fp: 28502.0000 - tn: 291498.0000 - fn: 28502.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6518 - val_tp: 12856.0000 - val_fp: 7144.0000 - val_tn: 72856.0000 - val_fn: 7144.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-35-36
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 37-37/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part10_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51413.0000 - fp: 28587.0000 - tn: 291413.0000 - fn: 28587.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9105 - val_loss: 0.6519 - val_tp: 12854.0000 - val_fp: 7146.0000 - val_tn: 72854.0000 - val_fn: 7146.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51456.0000 - fp: 28544.0000 - tn: 291456.0000 - fn: 28544.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9109 - val_loss: 0.6504 - val_tp: 12903.0000 - val_fp: 7097.0000 - val_tn: 72903.0000 - val_fn: 7097.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51565.0000 - fp: 28435.0000 - tn: 291565.0000 - fn: 28435.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51512.0000 - fp: 28488.0000 - tn: 291512.0000 - fn: 28488.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9104 - val_loss: 0.6508 - val_tp: 12888.0000 - val_fp: 7112.0000 - val_tn: 72888.0000 - val_fn: 7112.0000 - val_accuracy: 0.8578 - val_precision: 0.6444 - val_recall: 0.6444 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51528.0000 - fp: 28472.0000 - tn: 291528.0000 - fn: 28472.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6505 - val_tp: 12899.0000 - val_fp: 7101.0000 - val_tn: 72899.0000 - val_fn: 7101.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-36-37
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 38-38/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part11_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51513.0000 - fp: 28487.0000 - tn: 291513.0000 - fn: 28487.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9105 - val_loss: 0.6496 - val_tp: 12931.0000 - val_fp: 7069.0000 - val_tn: 72931.0000 - val_fn: 7069.0000 - val_accuracy: 0.8586 - val_precision: 0.6465 - val_recall: 0.6465 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51589.0000 - fp: 28411.0000 - tn: 291589.0000 - fn: 28411.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6524 - val_tp: 12842.0000 - val_fp: 7158.0000 - val_tn: 72842.0000 - val_fn: 7158.0000 - val_accuracy: 0.8568 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51481.0000 - fp: 28519.0000 - tn: 291481.0000 - fn: 28519.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9106 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51549.0000 - fp: 28451.0000 - tn: 291549.0000 - fn: 28451.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9108 - val_loss: 0.6505 - val_tp: 12898.0000 - val_fp: 7102.0000 - val_tn: 72898.0000 - val_fn: 7102.0000 - val_accuracy: 0.8580 - val_precision: 0.6449 - val_recall: 0.6449 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51550.0000 - fp: 28450.0000 - tn: 291550.0000 - fn: 28450.0000 - accuracy: 0.8577 - precision: 0.6444 - recall: 0.6444 - auc: 0.9110 - val_loss: 0.6515 - val_tp: 12866.0000 - val_fp: 7134.0000 - val_tn: 72866.0000 - val_fn: 7134.0000 - val_accuracy: 0.8573 - val_precision: 0.6433 - val_recall: 0.6433 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-37-38
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 39-39/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part12_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51486.0000 - fp: 28514.0000 - tn: 291486.0000 - fn: 28514.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9107 - val_loss: 0.6521 - val_tp: 12847.0000 - val_fp: 7153.0000 - val_tn: 72847.0000 - val_fn: 7153.0000 - val_accuracy: 0.8569 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51597.0000 - fp: 28403.0000 - tn: 291597.0000 - fn: 28403.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9114 - val_loss: 0.6502 - val_tp: 12910.0000 - val_fp: 7090.0000 - val_tn: 72910.0000 - val_fn: 7090.0000 - val_accuracy: 0.8582 - val_precision: 0.6455 - val_recall: 0.6455 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6503 - tp: 51631.0000 - fp: 28369.0000 - tn: 291631.0000 - fn: 28369.0000 - accuracy: 0.8582 - precision: 0.6454 - recall: 0.6454 - auc: 0.9113 - val_loss: 0.6507 - val_tp: 12894.0000 - val_fp: 7106.0000 - val_tn: 72894.0000 - val_fn: 7106.0000 - val_accuracy: 0.8579 - val_precision: 0.6447 - val_recall: 0.6447 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51488.0000 - fp: 28512.0000 - tn: 291488.0000 - fn: 28512.0000 - accuracy: 0.8574 - precision: 0.6436 - recall: 0.6436 - auc: 0.9111 - val_loss: 0.6512 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-38-39
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 40-40/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part13_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (579817, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51418.0000 - fp: 28582.0000 - tn: 291418.0000 - fn: 28582.0000 - accuracy: 0.8571 - precision: 0.6427 - recall: 0.6427 - auc: 0.9103 - val_loss: 0.6522 - val_tp: 12843.0000 - val_fp: 7157.0000 - val_tn: 72843.0000 - val_fn: 7157.0000 - val_accuracy: 0.8569 - val_precision: 0.6421 - val_recall: 0.6421 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 100000-200000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51491.0000 - fp: 28509.0000 - tn: 291491.0000 - fn: 28509.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9105 - val_loss: 0.6517 - val_tp: 12862.0000 - val_fp: 7138.0000 - val_tn: 72862.0000 - val_fn: 7138.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 200000-300000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51556.0000 - fp: 28444.0000 - tn: 291556.0000 - fn: 28444.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9112 - val_loss: 0.6500 - val_tp: 12916.0000 - val_fp: 7084.0000 - val_tn: 72916.0000 - val_fn: 7084.0000 - val_accuracy: 0.8583 - val_precision: 0.6458 - val_recall: 0.6458 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 300000-400000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51505.0000 - fp: 28495.0000 - tn: 291505.0000 - fn: 28495.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6523 - val_tp: 12838.0000 - val_fp: 7162.0000 - val_tn: 72838.0000 - val_fn: 7162.0000 - val_accuracy: 0.8568 - val_precision: 0.6419 - val_recall: 0.6419 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 400000-500000/579817
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51432.0000 - fp: 28568.0000 - tn: 291432.0000 - fn: 28568.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9107 - val_loss: 0.6520 - val_tp: 12850.0000 - val_fp: 7150.0000 - val_tn: 72850.0000 - val_fn: 7150.0000 - val_accuracy: 0.8570 - val_precision: 0.6425 - val_recall: 0.6425 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-39-40
[INFO] processing batch 500000-600000/579817
[33m[INFO] loading file 41-41/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_074818_111.log.part14_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9106 - val_loss: 0.6517 - val_tp: 12861.0000 - val_fp: 7139.0000 - val_tn: 72861.0000 - val_fn: 7139.0000 - val_accuracy: 0.8572 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51515.0000 - fp: 28485.0000 - tn: 291515.0000 - fn: 28485.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9111 - val_loss: 0.6515 - val_tp: 12868.0000 - val_fp: 7132.0000 - val_tn: 72868.0000 - val_fn: 7132.0000 - val_accuracy: 0.8574 - val_precision: 0.6434 - val_recall: 0.6434 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12876.0000 - val_fp: 7124.0000 - val_tn: 72876.0000 - val_fn: 7124.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51587.0000 - fp: 28413.0000 - tn: 291587.0000 - fn: 28413.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9111 - val_loss: 0.6517 - val_tp: 12860.0000 - val_fp: 7140.0000 - val_tn: 72860.0000 - val_fn: 7140.0000 - val_accuracy: 0.8572 - val_precision: 0.6430 - val_recall: 0.6430 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9110 - val_loss: 0.6494 - val_tp: 12937.0000 - val_fp: 7063.0000 - val_tn: 72937.0000 - val_fn: 7063.0000 - val_accuracy: 0.8587 - val_precision: 0.6468 - val_recall: 0.6468 - val_auc: 0.9117
[INFO] saving weights to checkpoints/dnn-epoch-010-files-40-41
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 42-42/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part01_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51459.0000 - fp: 28541.0000 - tn: 291459.0000 - fn: 28541.0000 - accuracy: 0.8573 - precision: 0.6432 - recall: 0.6432 - auc: 0.9105 - val_loss: 0.6527 - val_tp: 12826.0000 - val_fp: 7174.0000 - val_tn: 72826.0000 - val_fn: 7174.0000 - val_accuracy: 0.8565 - val_precision: 0.6413 - val_recall: 0.6413 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6512 - tp: 51511.0000 - fp: 28489.0000 - tn: 291511.0000 - fn: 28489.0000 - accuracy: 0.8576 - precision: 0.6439 - recall: 0.6439 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12882.0000 - val_fp: 7118.0000 - val_tn: 72882.0000 - val_fn: 7118.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51499.0000 - fp: 28501.0000 - tn: 291499.0000 - fn: 28501.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9108 - val_loss: 0.6519 - val_tp: 12853.0000 - val_fp: 7147.0000 - val_tn: 72853.0000 - val_fn: 7147.0000 - val_accuracy: 0.8571 - val_precision: 0.6427 - val_recall: 0.6427 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51494.0000 - fp: 28506.0000 - tn: 291494.0000 - fn: 28506.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6501 - val_tp: 12917.0000 - val_fp: 7083.0000 - val_tn: 72917.0000 - val_fn: 7083.0000 - val_accuracy: 0.8583 - val_precision: 0.6459 - val_recall: 0.6459 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6507 - tp: 51584.0000 - fp: 28416.0000 - tn: 291584.0000 - fn: 28416.0000 - accuracy: 0.8579 - precision: 0.6448 - recall: 0.6448 - auc: 0.9108 - val_loss: 0.6513 - val_tp: 12875.0000 - val_fp: 7125.0000 - val_tn: 72875.0000 - val_fn: 7125.0000 - val_accuracy: 0.8575 - val_precision: 0.6438 - val_recall: 0.6438 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-41-42
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 43-43/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part02_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6514 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51529.0000 - fp: 28471.0000 - tn: 291529.0000 - fn: 28471.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6528 - val_tp: 12824.0000 - val_fp: 7176.0000 - val_tn: 72824.0000 - val_fn: 7176.0000 - val_accuracy: 0.8565 - val_precision: 0.6412 - val_recall: 0.6412 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51387.0000 - fp: 28613.0000 - tn: 291387.0000 - fn: 28613.0000 - accuracy: 0.8569 - precision: 0.6423 - recall: 0.6423 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51518.0000 - fp: 28482.0000 - tn: 291518.0000 - fn: 28482.0000 - accuracy: 0.8576 - precision: 0.6440 - recall: 0.6440 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51591.0000 - fp: 28409.0000 - tn: 291591.0000 - fn: 28409.0000 - accuracy: 0.8580 - precision: 0.6449 - recall: 0.6449 - auc: 0.9112 - val_loss: 0.6489 - val_tp: 12952.0000 - val_fp: 7048.0000 - val_tn: 72952.0000 - val_fn: 7048.0000 - val_accuracy: 0.8590 - val_precision: 0.6476 - val_recall: 0.6476 - val_auc: 0.9119
[INFO] saving weights to checkpoints/dnn-epoch-010-files-42-43
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 44-44/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part03_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51452.0000 - fp: 28548.0000 - tn: 291452.0000 - fn: 28548.0000 - accuracy: 0.8573 - precision: 0.6431 - recall: 0.6431 - auc: 0.9111 - val_loss: 0.6520 - val_tp: 12855.0000 - val_fp: 7145.0000 - val_tn: 72855.0000 - val_fn: 7145.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9110 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51543.0000 - fp: 28457.0000 - tn: 291543.0000 - fn: 28457.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9112 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51427.0000 - fp: 28573.0000 - tn: 291427.0000 - fn: 28573.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9103 - val_loss: 0.6508 - val_tp: 12891.0000 - val_fp: 7109.0000 - val_tn: 72891.0000 - val_fn: 7109.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51537.0000 - fp: 28463.0000 - tn: 291537.0000 - fn: 28463.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-43-44
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 45-45/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part04_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6504 - tp: 51620.0000 - fp: 28380.0000 - tn: 291620.0000 - fn: 28380.0000 - accuracy: 0.8581 - precision: 0.6453 - recall: 0.6453 - auc: 0.9109 - val_loss: 0.6514 - val_tp: 12869.0000 - val_fp: 7131.0000 - val_tn: 72869.0000 - val_fn: 7131.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51538.0000 - fp: 28462.0000 - tn: 291538.0000 - fn: 28462.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9106 - val_loss: 0.6509 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51564.0000 - fp: 28436.0000 - tn: 291564.0000 - fn: 28436.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9113 - val_loss: 0.6504 - val_tp: 12904.0000 - val_fp: 7096.0000 - val_tn: 72904.0000 - val_fn: 7096.0000 - val_accuracy: 0.8581 - val_precision: 0.6452 - val_recall: 0.6452 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6506 - tp: 51590.0000 - fp: 28410.0000 - tn: 291590.0000 - fn: 28410.0000 - accuracy: 0.8579 - precision: 0.6449 - recall: 0.6449 - auc: 0.9113 - val_loss: 0.6523 - val_tp: 12844.0000 - val_fp: 7156.0000 - val_tn: 72844.0000 - val_fn: 7156.0000 - val_accuracy: 0.8569 - val_precision: 0.6422 - val_recall: 0.6422 - val_auc: 0.9105
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6521 - tp: 51395.0000 - fp: 28605.0000 - tn: 291395.0000 - fn: 28605.0000 - accuracy: 0.8570 - precision: 0.6424 - recall: 0.6424 - auc: 0.9106 - val_loss: 0.6507 - val_tp: 12896.0000 - val_fp: 7104.0000 - val_tn: 72896.0000 - val_fn: 7104.0000 - val_accuracy: 0.8579 - val_precision: 0.6448 - val_recall: 0.6448 - val_auc: 0.9112
[INFO] saving weights to checkpoints/dnn-epoch-010-files-44-45
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 46-46/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part05_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9110 - val_loss: 0.6501 - val_tp: 12913.0000 - val_fp: 7087.0000 - val_tn: 72913.0000 - val_fn: 7087.0000 - val_accuracy: 0.8583 - val_precision: 0.6457 - val_recall: 0.6457 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51464.0000 - fp: 28536.0000 - tn: 291464.0000 - fn: 28536.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6510 - val_tp: 12883.0000 - val_fp: 7117.0000 - val_tn: 72883.0000 - val_fn: 7117.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6510 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9113 - val_loss: 0.6510 - val_tp: 12885.0000 - val_fp: 7115.0000 - val_tn: 72885.0000 - val_fn: 7115.0000 - val_accuracy: 0.8577 - val_precision: 0.6442 - val_recall: 0.6442 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51502.0000 - fp: 28498.0000 - tn: 291502.0000 - fn: 28498.0000 - accuracy: 0.8575 - precision: 0.6438 - recall: 0.6438 - auc: 0.9109 - val_loss: 0.6499 - val_tp: 12929.0000 - val_fp: 7071.0000 - val_tn: 72929.0000 - val_fn: 7071.0000 - val_accuracy: 0.8586 - val_precision: 0.6464 - val_recall: 0.6464 - val_auc: 0.9116
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51569.0000 - fp: 28431.0000 - tn: 291569.0000 - fn: 28431.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6513 - val_tp: 12873.0000 - val_fp: 7127.0000 - val_tn: 72873.0000 - val_fn: 7127.0000 - val_accuracy: 0.8575 - val_precision: 0.6436 - val_recall: 0.6436 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-45-46
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 47-47/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part06_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51601.0000 - fp: 28399.0000 - tn: 291601.0000 - fn: 28399.0000 - accuracy: 0.8580 - precision: 0.6450 - recall: 0.6450 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51559.0000 - fp: 28441.0000 - tn: 291559.0000 - fn: 28441.0000 - accuracy: 0.8578 - precision: 0.6445 - recall: 0.6445 - auc: 0.9111 - val_loss: 0.6514 - val_tp: 12871.0000 - val_fp: 7129.0000 - val_tn: 72871.0000 - val_fn: 7129.0000 - val_accuracy: 0.8574 - val_precision: 0.6435 - val_recall: 0.6435 - val_auc: 0.9109
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51468.0000 - fp: 28532.0000 - tn: 291468.0000 - fn: 28532.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9108 - val_loss: 0.6528 - val_tp: 12822.0000 - val_fp: 7178.0000 - val_tn: 72822.0000 - val_fn: 7178.0000 - val_accuracy: 0.8564 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51493.0000 - fp: 28507.0000 - tn: 291493.0000 - fn: 28507.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6511 - val_tp: 12881.0000 - val_fp: 7119.0000 - val_tn: 72881.0000 - val_fn: 7119.0000 - val_accuracy: 0.8576 - val_precision: 0.6441 - val_recall: 0.6441 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9110 - val_loss: 0.6504 - val_tp: 12909.0000 - val_fp: 7091.0000 - val_tn: 72909.0000 - val_fn: 7091.0000 - val_accuracy: 0.8582 - val_precision: 0.6454 - val_recall: 0.6454 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-46-47
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 48-48/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part07_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51525.0000 - fp: 28475.0000 - tn: 291525.0000 - fn: 28475.0000 - accuracy: 0.8576 - precision: 0.6441 - recall: 0.6441 - auc: 0.9104 - val_loss: 0.6526 - val_tp: 12830.0000 - val_fp: 7170.0000 - val_tn: 72830.0000 - val_fn: 7170.0000 - val_accuracy: 0.8566 - val_precision: 0.6415 - val_recall: 0.6415 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51497.0000 - fp: 28503.0000 - tn: 291497.0000 - fn: 28503.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9109 - val_loss: 0.6511 - val_tp: 12879.0000 - val_fp: 7121.0000 - val_tn: 72879.0000 - val_fn: 7121.0000 - val_accuracy: 0.8576 - val_precision: 0.6439 - val_recall: 0.6439 - val_auc: 0.9110
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6509 - tp: 51547.0000 - fp: 28453.0000 - tn: 291547.0000 - fn: 28453.0000 - accuracy: 0.8577 - precision: 0.6443 - recall: 0.6443 - auc: 0.9111 - val_loss: 0.6502 - val_tp: 12911.0000 - val_fp: 7089.0000 - val_tn: 72911.0000 - val_fn: 7089.0000 - val_accuracy: 0.8582 - val_precision: 0.6456 - val_recall: 0.6456 - val_auc: 0.9114
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6508 - tp: 51566.0000 - fp: 28434.0000 - tn: 291566.0000 - fn: 28434.0000 - accuracy: 0.8578 - precision: 0.6446 - recall: 0.6446 - auc: 0.9107 - val_loss: 0.6516 - val_tp: 12863.0000 - val_fp: 7137.0000 - val_tn: 72863.0000 - val_fn: 7137.0000 - val_accuracy: 0.8573 - val_precision: 0.6431 - val_recall: 0.6431 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6505 - tp: 51606.0000 - fp: 28394.0000 - tn: 291606.0000 - fn: 28394.0000 - accuracy: 0.8580 - precision: 0.6451 - recall: 0.6451 - auc: 0.9111 - val_loss: 0.6503 - val_tp: 12905.0000 - val_fp: 7095.0000 - val_tn: 72905.0000 - val_fn: 7095.0000 - val_accuracy: 0.8581 - val_precision: 0.6453 - val_recall: 0.6453 - val_auc: 0.9113
[INFO] saving weights to checkpoints/dnn-epoch-010-files-47-48
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 49-49/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part08_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6511 - tp: 51532.0000 - fp: 28468.0000 - tn: 291532.0000 - fn: 28468.0000 - accuracy: 0.8577 - precision: 0.6442 - recall: 0.6442 - auc: 0.9105 - val_loss: 0.6515 - val_tp: 12865.0000 - val_fp: 7135.0000 - val_tn: 72865.0000 - val_fn: 7135.0000 - val_accuracy: 0.8573 - val_precision: 0.6432 - val_recall: 0.6432 - val_auc: 0.9108
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51430.0000 - fp: 28570.0000 - tn: 291430.0000 - fn: 28570.0000 - accuracy: 0.8571 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6500 - val_tp: 12924.0000 - val_fp: 7076.0000 - val_tn: 72924.0000 - val_fn: 7076.0000 - val_accuracy: 0.8585 - val_precision: 0.6462 - val_recall: 0.6462 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51469.0000 - fp: 28531.0000 - tn: 291469.0000 - fn: 28531.0000 - accuracy: 0.8573 - precision: 0.6434 - recall: 0.6434 - auc: 0.9105 - val_loss: 0.6526 - val_tp: 12829.0000 - val_fp: 7171.0000 - val_tn: 72829.0000 - val_fn: 7171.0000 - val_accuracy: 0.8566 - val_precision: 0.6414 - val_recall: 0.6414 - val_auc: 0.9104
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51492.0000 - fp: 28508.0000 - tn: 291492.0000 - fn: 28508.0000 - accuracy: 0.8575 - precision: 0.6436 - recall: 0.6436 - auc: 0.9112 - val_loss: 0.6498 - val_tp: 12922.0000 - val_fp: 7078.0000 - val_tn: 72922.0000 - val_fn: 7078.0000 - val_accuracy: 0.8584 - val_precision: 0.6461 - val_recall: 0.6461 - val_auc: 0.9115
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6513 - tp: 51495.0000 - fp: 28505.0000 - tn: 291495.0000 - fn: 28505.0000 - accuracy: 0.8575 - precision: 0.6437 - recall: 0.6437 - auc: 0.9107 - val_loss: 0.6508 - val_tp: 12890.0000 - val_fp: 7110.0000 - val_tn: 72890.0000 - val_fn: 7110.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-48-49
[INFO] processing batch 500000-600000/519975
[33m[INFO] loading file 50-50/50 on epoch 10/10[0m
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/train/2015-12-31_130240_112.log.part09_sorted-labeled.csv
[INFO] concatenate the files
[INFO] process dataset, shape: (519975, 18)
[INFO] sampling 1.0
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['appi_name', 'classification', 'dst', 'i/f_dir', 'i/f_name',
       'modbus_function_code', 'modbus_function_description',
       'modbus_transaction_id', 'orig', 'proto', 'proxy_src_ip', 's_port',
       'scada_tag', 'service', 'src', 'type'],
      dtype='object')
[INFO] processing batch 0-100000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6519 - tp: 51422.0000 - fp: 28578.0000 - tn: 291422.0000 - fn: 28578.0000 - accuracy: 0.8571 - precision: 0.6428 - recall: 0.6428 - auc: 0.9104 - val_loss: 0.6528 - val_tp: 12823.0000 - val_fp: 7177.0000 - val_tn: 72823.0000 - val_fn: 7177.0000 - val_accuracy: 0.8565 - val_precision: 0.6411 - val_recall: 0.6411 - val_auc: 0.9103
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 100000-200000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6514 - tp: 51482.0000 - fp: 28518.0000 - tn: 291482.0000 - fn: 28518.0000 - accuracy: 0.8574 - precision: 0.6435 - recall: 0.6435 - auc: 0.9110 - val_loss: 0.6507 - val_tp: 12892.0000 - val_fp: 7108.0000 - val_tn: 72892.0000 - val_fn: 7108.0000 - val_accuracy: 0.8578 - val_precision: 0.6446 - val_recall: 0.6446 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 200000-300000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6518 - tp: 51433.0000 - fp: 28567.0000 - tn: 291433.0000 - fn: 28567.0000 - accuracy: 0.8572 - precision: 0.6429 - recall: 0.6429 - auc: 0.9106 - val_loss: 0.6520 - val_tp: 12849.0000 - val_fp: 7151.0000 - val_tn: 72849.0000 - val_fn: 7151.0000 - val_accuracy: 0.8570 - val_precision: 0.6424 - val_recall: 0.6424 - val_auc: 0.9106
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 300000-400000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6516 - tp: 51461.0000 - fp: 28539.0000 - tn: 291461.0000 - fn: 28539.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9108 - val_loss: 0.6508 - val_tp: 12889.0000 - val_fp: 7111.0000 - val_tn: 72889.0000 - val_fn: 7111.0000 - val_accuracy: 0.8578 - val_precision: 0.6445 - val_recall: 0.6445 - val_auc: 0.9111
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 400000-500000/519975
[INFO] breaking into predictors and prediction...
[INFO] creating train/test split: 0.2
[INFO] fitting model
Train on 80000 samples, validate on 20000 samples
Epoch 1/1
 - 3s - loss: 0.6515 - tp: 51467.0000 - fp: 28533.0000 - tn: 291467.0000 - fn: 28533.0000 - accuracy: 0.8573 - precision: 0.6433 - recall: 0.6433 - auc: 0.9105 - val_loss: 0.6518 - val_tp: 12857.0000 - val_fp: 7143.0000 - val_tn: 72857.0000 - val_fn: 7143.0000 - val_accuracy: 0.8571 - val_precision: 0.6428 - val_recall: 0.6428 - val_auc: 0.9107
train.py:186: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

  df = pd.concat(df_from_each_file, ignore_index=True)
[INFO] saving weights to checkpoints/dnn-epoch-010-files-49-50
[INFO] processing batch 500000-600000/519975
[33m[LOSS] 0.6517966634750366[0m
[CHECKING EARLY STOP]: currentLoss < min_delta ? => 0.6517966634750366  <  0.001
--- 7625.822843551636 seconds ---
2020-02-07 00:46:01.509685: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-07 00:46:01.509733: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-07 00:46:01.509739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-07 00:46:01.997898: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-02-07 00:46:01.997918: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-02-07 00:46:01.997935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (brussels): /proc/driver/nvidia/version does not exist
2020-02-07 00:46:01.998039: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-07 00:46:02.021915: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3312000000 Hz
2020-02-07 00:46:02.022300: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a01ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-07 00:46:02.022335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Using TensorFlow backend.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
=============================
        SCORING v0.4
=============================
Date: 2020-02-07 00:46:01.994843
[33m[INFO] using Sequential Dense layers[0m
[INFO] adding core layer 0
[INFO] created DNN
loading weights: checkpoints/*
loading file checkpoints/dnn-epoch-010-files-9-10
[33m[INFO] model summary:[0m
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 2)                 32        
_________________________________________________________________
dropout_1 (Dropout)          (None, 2)                 0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 12        
_________________________________________________________________
dropout_2 (Dropout)          (None, 4)                 0         
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 10        
_________________________________________________________________
dropout_3 (Dropout)          (None, 2)                 0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 3         
_________________________________________________________________
dropout_4 (Dropout)          (None, 1)                 0         
_________________________________________________________________
dense_5 (Dense)              (None, 5)                 10        
=================================================================
Total params: 67
Trainable params: 67
Non-trainable params: 0
_________________________________________________________________
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_130240_112.log.part10_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9992%,0.0:0.0008%]
[INFO] ** type:[1.0:99.9984%,0.5:0.0014%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9984%,0.5:0.0016%]
[INFO] ** i/f_dir:[0.0:99.9986%,1.0:0.0014%]
[INFO] ** src:[0.0666666667:38.114%,0.9333333333:26.0964%,0.6666666667:18.2424%,0.3333333333:17.543%,0.1333333333:0.0016%,0.0:0.0012%,0.2:0.001%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.3686%,0.9411764706:20.8412%,0.8823529412000001:18.2422%,0.5294117647:17.5434%,0.2941176471:0.0016%,0.0:0.0014%,0.3529411765:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.997%,0.0:0.0016%,1.0:0.0014%]
[INFO] ** appi_name:[0.0:99.9962%,0.0384615385:0.0016%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.3846153846:0.0002%,0.34615384619999995:0.0002%,0.4230769231:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.114%,0.0:26.0964%,0.9333333333:18.2424%,0.4:17.543%,0.5333333333:0.0016%,0.1333333333:0.0012%,0.0666666667:0.001%,0.6:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9962%,0.0:0.0036%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9988%,0.0:49.9974%,0.4:0.0036%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0954%,0.6:20.841%,0.8:18.242%,0.0:17.5424%,0.4:17.2726%,0.2:0.0066%]
[INFO] ** service:[0.7025755984000001:99.997%,0.0:0.0016%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0956%,0.8139250565:20.8412%,0.8029830673999999:18.242%,0.8149336757:17.5424%,0.8137722355:17.2728%,0.0:0.0016%,0.7081881533:0.0008%,0.814841983:0.0006%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.0020936488:0.0002%,0.8030136315999999:0.0002%,0.7806864723:0.0002%]
[INFO] ** classification:[normal:79.7796%,Single Stage Single Point:20.2204%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64261[0m
[33m[INFO] metrics:[0m
loss :  1.8039212028503417
tp :  64261.0
fp :  35739.0
tn :  364261.0
fn :  35739.0
accuracy :  0.857053279876709
precision :  0.6426100134849548
recall :  0.6426100134849548
auc :  0.9106525182723999

y_eval {0: 64261, 1: 35739}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[64261     0     0     0     0]
 [35739     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] Validation score: [33m0.64231[0m
[33m[INFO] metrics:[0m
loss :  1.8054299755859375
tp :  64231.0
fp :  35769.0
tn :  364231.0
fn :  35769.0
accuracy :  0.856931746006012
precision :  0.6423100233078003
recall :  0.6423100233078003
auc :  0.9105774760246277

y_eval {0: 64231, 1: 35769}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64231     0     0     0     0]
 [35769     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[128492      0      0      0      0]
 [ 71508      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.70406[0m
[33m[INFO] metrics:[0m
loss :  1.4948746328160167
tp :  70406.0
fp :  29594.0
tn :  370406.0
fn :  29594.0
accuracy :  0.8816267251968384
precision :  0.7040600180625916
recall :  0.7040600180625916
auc :  0.9260150194168091

y_eval {0: 70406, 1: 29594}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70406     0     0     0     0]
 [29594     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[198898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[298898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[398898      0      0      0      0]
 [101102      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_181648_113.log.part08_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9948%,1.0:0.0052%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9948%,0.5:0.0052%]
[INFO] ** i/f_dir:[0.0:99.9948%,1.0:0.0052%]
[INFO] ** src:[0.0666666667:38.4402%,0.9333333333:25.9738%,0.6666666667:18.1202%,0.3333333333:17.4598%,0.8:0.0052%,0.2666666667:0.0004%,0.5333333333:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.345%,0.9411764706:21.0682%,0.8823529412000001:18.1202%,0.5294117647:17.4594%,0.2941176471:0.0052%,0.0:0.0012%,0.7647058823999999:0.0004%,1.0:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9946%,0.0:0.0052%,1.0:0.0002%]
[INFO] ** appi_name:[0.0:99.9942%,0.0384615385:0.0052%,0.4230769231:0.0002%,0.1538461538:0.0002%,0.4615384615:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4402%,0.0:25.9738%,0.9333333333:18.1202%,0.4:17.4598%,0.5333333333:0.0052%,0.8:0.0004%,0.6:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9942%,0.0:0.0058%]
[INFO] ** modbus_function_description:[0.2:49.998%,0.0:49.9962%,0.4:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9726%,0.6:21.0682%,0.8:18.1198%,0.0:17.459%,0.4:17.3718%,0.2:0.0086%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.0052%,0.0021789908:0.0004%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:25.973%,0.8139250565:21.0682%,0.8029830673999999:18.12%,0.8149336757:17.4592%,0.8137722355:17.372%,0.0:0.0052%,0.814841983:0.0006%,0.8343113882:0.0004%,0.9137019378:0.0004%,0.8059172320999999:0.0002%,0.8030136315999999:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%]
[INFO] ** classification:[normal:80.1196%,Multi Stage Multi Point:14.47%,Single Stage Multi Point:5.4104%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.72948[0m
[33m[INFO] metrics:[0m
loss :  5.98731145948708
tp :  72948.0
fp :  27052.0
tn :  372948.0
fn :  27052.0
accuracy :  0.8917929530143738
precision :  0.7294800281524658
recall :  0.7294800281524658
auc :  0.7971100211143494

y_eval {0: 72948, 2: 27052}
pred {0: 100000}
[INFO] confusion matrix for file 
[[72948     0     0     0     0]
 [    0     0     0     0     0]
 [27052     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[471846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[571846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[671846      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.7477[0m
[33m[INFO] metrics:[0m
loss :  5.584494836030901
tp :  74770.0
fp :  25230.0
tn :  374770.0
fn :  25230.0
accuracy :  0.8990800976753235
precision :  0.7476999759674072
recall :  0.7476999759674072
auc :  0.8107749819755554

y_eval {0: 74770, 4: 25230}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74770     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [25230     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[746616      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 25230      0      0      0      0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 4 0 ... 4 0 0] (100000,)
[INFO] Validation score: [33m0.5288[0m
[33m[INFO] metrics:[0m
loss :  10.424043615722656
tp :  52880.0
fp :  47120.0
tn :  352880.0
fn :  47120.0
accuracy :  0.8115204572677612
precision :  0.5288000106811523
recall :  0.5288000106811523
auc :  0.646600067615509

y_eval {0: 52880, 4: 47120}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52880     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47120     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[799496      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [ 72350      0      0      0      0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_181648_113.log.part09_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9966%,1.0:0.0034%]
[INFO] ** type:[1.0:99.9996%,0.5:0.0004%]
[INFO] ** i/f_name:[0.0:99.9938%,0.5:0.0062%]
[INFO] ** i/f_dir:[0.0:99.9942%,1.0:0.0058%]
[INFO] ** src:[0.0666666667:38.4204%,0.9333333333:25.9634%,0.6666666667:18.123%,0.3333333333:17.486%,0.8:0.0034%,0.1333333333:0.0028%,0.5333333333:0.0006%,0.2666666667:0.0004%]
[INFO] ** dst:[0.1764705882:43.3316%,0.9411764706:21.0518%,0.8823529412000001:18.123%,0.5294117647:17.486%,0.2941176471:0.0062%,0.0:0.0008%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9934%,0.0:0.0062%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9934%,0.0384615385:0.0062%,0.3076923077:0.0002%,0.9615384615000001:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4204%,0.0:25.9634%,0.9333333333:18.123%,0.4:17.486%,0.5333333333:0.0062%,0.6:0.0006%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9934%,0.0:0.0066%]
[INFO] ** modbus_function_description:[0.2:49.9972%,0.0:49.9962%,0.4:0.0066%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9624%,0.6:21.0518%,0.8:18.1226%,0.0:17.4856%,0.4:17.3686%,0.2:0.009%]
[INFO] ** service:[0.7025755984000001:99.9934%,0.0:0.0062%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:25.9628%,0.8139250565:21.0518%,0.8029830673999999:18.1226%,0.8149336757:17.4858%,0.8137722355:17.3686%,0.0:0.0062%,0.8059172320999999:0.0006%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.8343113882:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:73.9096%,Multi Stage Multi Point:26.0904%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 4 0 ... 4 4 4] (100000,)
[INFO] Validation score: [33m0.52975[0m
[33m[INFO] metrics:[0m
loss :  10.403040550231934
tp :  52975.0
fp :  47025.0
tn :  352975.0
fn :  47025.0
accuracy :  0.8118997812271118
precision :  0.5297499895095825
recall :  0.5297499895095825
auc :  0.6473124623298645

y_eval {0: 52975, 4: 47025}
pred {0: 100000}
[INFO] confusion matrix for file 
[[52975     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [47025     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[852471      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [119375      0      0      0      0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [4 0 4 ... 0 4 0] (100000,)
[INFO] Validation score: [33m0.53029[0m
[33m[INFO] metrics:[0m
loss :  10.391101965637207
tp :  53029.0
fp :  46971.0
tn :  353029.0
fn :  46971.0
accuracy :  0.812116801738739
precision :  0.5302900075912476
recall :  0.5302900075912476
auc :  0.6477175354957581

y_eval {0: 53029, 4: 46971}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53029     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [46971     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[905500      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [166346      0      0      0      0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [4 4 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.63544[0m
[33m[INFO] metrics:[0m
loss :  8.066394087966978
tp :  63544.0
fp :  36456.0
tn :  363544.0
fn :  36456.0
accuracy :  0.85417640209198
precision :  0.6354399919509888
recall :  0.6354399919509888
auc :  0.726580023765564

y_eval {0: 63544, 4: 36456}
pred {0: 100000}
[INFO] confusion matrix for file 
[[63544     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [36456     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[969044      0      0      0      0]
 [101102      0      0      0      0]
 [ 27052      0      0      0      0]
 [     0      0      0      0      0]
 [202802      0      0      0      0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1069044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1169044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2015-12-31_233049_114.log.part11_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:99.9994%,0.5:0.0004%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9968%,0.5:0.0032%]
[INFO] ** i/f_dir:[0.0:99.9972%,1.0:0.0028%]
[INFO] ** src:[0.0666666667:38.4512%,0.9333333333:25.9642%,0.6666666667:18.089%,0.3333333333:17.4908%,0.1333333333:0.0028%,0.0:0.0008%,0.2666666667:0.0004%,0.5333333333:0.0004%,0.8:0.0004%]
[INFO] ** dst:[0.1764705882:43.3436%,0.9411764706:21.0714%,0.8823529412000001:18.0896%,0.5294117647:17.4906%,0.2941176471:0.0032%,0.0:0.001%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9964%,0.0:0.0032%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9956%,0.0384615385:0.0032%,0.3846153846:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.4512%,0.0:25.9642%,0.9333333333:18.089%,0.4:17.4908%,0.5333333333:0.0032%,0.1333333333:0.0008%,0.6:0.0004%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9956%,0.0:0.0042%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.999%,0.0:49.9966%,0.4:0.0042%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:25.9632%,0.6:21.0714%,0.8:18.0886%,0.0:17.4902%,0.4:17.3796%,0.2:0.007%]
[INFO] ** service:[0.7025755984000001:99.9964%,0.0:0.0032%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:25.9636%,0.8139250565:21.0714%,0.8029830673999999:18.0886%,0.8149336757:17.4904%,0.8137722355:17.3798%,0.0:0.0032%,0.8896631823000001:0.0008%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.814841983:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:95.0874%,Single Stage Single Point:4.9126%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 9, 'proto': 3, 'appi_name': 8, 'proxy_src_ip': 8, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1269044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1369044       0       0       0       0]
 [ 101102       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.92639[0m
[33m[INFO] metrics:[0m
loss :  0.37672452041059734
tp :  92639.0
fp :  7361.0
tn :  392639.0
fn :  7361.0
accuracy :  0.9705646634101868
precision :  0.9263899922370911
recall :  0.9263899922370911
auc :  0.9815974831581116

y_eval {0: 92639, 1: 7361}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92639     0     0     0     0]
 [ 7361     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1461683       0       0       0       0]
 [ 108463       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.82798[0m
[33m[INFO] metrics:[0m
loss :  0.8716516622126103
tp :  82798.0
fp :  17202.0
tn :  382798.0
fn :  17202.0
accuracy :  0.9312011003494263
precision :  0.8279799818992615
recall :  0.8279799818992615
auc :  0.9569950103759766

y_eval {0: 82798, 1: 17202}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82798     0     0     0     0]
 [17202     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1544481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1644481       0       0       0       0]
 [ 125665       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9976%,1.0:0.0024%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9966%,0.5:0.0034%]
[INFO] ** i/f_dir:[0.0:99.9966%,1.0:0.0034%]
[INFO] ** src:[0.0666666667:38.1462%,0.9333333333:26.099%,0.6666666667:18.1904%,0.3333333333:17.5592%,0.8:0.0028%,0.1333333333:0.001%,1.0:0.0006%,0.2666666667:0.0004%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.376%,0.9411764706:20.8688%,0.8823529412000001:18.1902%,0.5294117647:17.5592%,0.2941176471:0.0034%,0.0:0.0008%,0.3529411765:0.0004%,0.4705882353:0.0004%,0.6470588235:0.0004%,0.4117647059:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9958%,0.0:0.0034%,1.0:0.0008%]
[INFO] ** appi_name:[0.0:99.9952%,0.0384615385:0.0034%,0.5384615385:0.0006%,0.3076923077:0.0004%,0.4230769231:0.0002%,0.0769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1462%,0.0:26.099%,0.9333333333:18.1904%,0.4:17.5592%,0.5333333333:0.0034%,0.7333333333:0.0006%,0.6:0.0004%,0.4666666667:0.0004%,0.8:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9952%,0.0:0.0048%]
[INFO] ** modbus_function_description:[0.2:49.9978%,0.0:49.9974%,0.4:0.0048%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0982%,0.6:20.8688%,0.8:18.19%,0.0:17.5588%,0.4:17.2772%,0.2:0.007%]
[INFO] ** service:[0.7025755984000001:99.9952%,0.0:0.0034%,0.002116286:0.0006%,0.08394601119999999:0.0004%,0.0021633145999999997:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0986%,0.8139250565:20.8688%,0.8029830673999999:18.1902%,0.8149336757:17.559%,0.8137722355:17.2774%,0.0:0.0034%,0.8059172320999999:0.0004%,0.8343113882:0.0002%,0.814841983:0.0002%,0.9228712024:0.0002%,0.0021089309:0.0002%,0.7616602481999999:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%,0.7840485359999999:0.0002%,0.8030136315999999:0.0002%,0.8086374473000001:0.0002%]
[INFO] ** classification:[normal:84.2104%,Single Stage Single Point:15.7896%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 6, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.70708[0m
[33m[INFO] metrics:[0m
loss :  1.4796863396149873
tp :  70708.0
fp :  29292.0
tn :  370708.0
fn :  29292.0
accuracy :  0.8828411102294922
precision :  0.7070800065994263
recall :  0.7070800065994263
auc :  0.926770031452179

y_eval {0: 70708, 1: 29292}
pred {0: 100000}
[INFO] confusion matrix for file 
[[70708     0     0     0     0]
 [29292     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1715189       0       0       0       0]
 [ 154957       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64215[0m
[33m[INFO] metrics:[0m
loss :  1.806234652671814
tp :  64215.0
fp :  35785.0
tn :  364215.0
fn :  35785.0
accuracy :  0.856867790222168
precision :  0.6421499848365784
recall :  0.6421499848365784
auc :  0.9105375409126282

y_eval {0: 64215, 1: 35785}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64215     0     0     0     0]
 [35785     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1779404       0       0       0       0]
 [ 190742       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.86129[0m
[33m[INFO] metrics:[0m
loss :  0.7041278059113025
tp :  86129.0
fp :  13871.0
tn :  386129.0
fn :  13871.0
accuracy :  0.9445148706436157
precision :  0.8612899780273438
recall :  0.8612899780273438
auc :  0.9653224945068359

y_eval {0: 86129, 1: 13871}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86129     0     0     0     0]
 [13871     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[1865533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[1965533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2065533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9964%,1.0:0.0036%]
[INFO] ** type:[1.0:99.9994%,0.5:0.0004%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.996%,0.5:0.004%]
[INFO] ** i/f_dir:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** src:[0.0666666667:38.049%,0.9333333333:26.1306%,0.6666666667:18.2264%,0.3333333333:17.587%,0.8:0.0036%,0.0:0.0014%,0.2:0.001%,0.1333333333:0.0004%,0.5333333333:0.0002%,0.4:0.0002%,0.6:0.0002%]
[INFO] ** dst:[0.1764705882:43.355%,0.9411764706:20.8256%,0.8823529412000001:18.226%,0.5294117647:17.5868%,0.2941176471:0.004%,0.3529411765:0.001%,0.0:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9942%,0.0:0.004%,1.0:0.0018%]
[INFO] ** appi_name:[0.0:99.9932%,0.0384615385:0.004%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.1923076923:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.3846153846:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.049%,0.0:26.1306%,0.9333333333:18.2264%,0.4:17.587%,0.5333333333:0.004%,0.1333333333:0.0014%,0.0666666667:0.001%,1.0:0.0002%,0.6:0.0002%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9932%,0.0:0.0066%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9974%,0.0:49.9958%,0.4:0.0066%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.13%,0.6:20.8244%,0.8:18.2258%,0.0:17.5864%,0.4:17.2242%,0.2:0.0092%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.004%,0.0021476384:0.0006%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1304%,0.8139250565:20.8246%,0.8029830673999999:18.226%,0.8149336757:17.5866%,0.8137722355:17.2244%,0.0:0.004%,0.7431230515:0.0008%,0.0020936488:0.0006%,0.814841983:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.8030441959000001:0.0002%,0.7967938137999999:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.1074484993:0.0002%,0.8030136315999999:0.0002%,0.8059172320999999:0.0002%]
[INFO] ** classification:[normal:97.1716%,Single Stage Single Point:2.8284%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2165533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2265533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2365533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2465533       0       0       0       0]
 [ 204613       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 1 1] (100000,)
[INFO] Validation score: [33m0.85858[0m
[33m[INFO] metrics:[0m
loss :  0.7177570360732078
tp :  85858.0
fp :  14142.0
tn :  385858.0
fn :  14142.0
accuracy :  0.9434324502944946
precision :  0.8585799932479858
recall :  0.8585799932479858
auc :  0.9646449685096741

y_eval {0: 85858, 1: 14142}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85858     0     0     0     0]
 [14142     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2551391       0       0       0       0]
 [ 218755       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_151435_117.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9986%,1.0:0.0014%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.998%,0.5:0.002%]
[INFO] ** i/f_dir:[0.0:99.998%,1.0:0.002%]
[INFO] ** src:[0.0666666667:38.1186%,0.9333333333:26.0918%,0.6666666667:18.2288%,0.3333333333:17.558%,0.8:0.0018%,0.1333333333:0.0006%,0.5333333333:0.0004%]
[INFO] ** dst:[0.1764705882:43.3702%,0.9411764706:20.8392%,0.8823529412000001:18.2288%,0.5294117647:17.5578%,0.2941176471:0.002%,0.0:0.0012%,0.23529411760000002:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%]
[INFO] ** proto:[0.5:99.9976%,0.0:0.002%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9976%,0.0384615385:0.002%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1186%,0.0:26.0918%,0.9333333333:18.2288%,0.4:17.558%,0.5333333333:0.002%,0.6:0.0004%,0.4666666667:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.9976%,0.0:0.0024%]
[INFO] ** modbus_function_description:[0.2:49.9998%,0.0:49.9978%,0.4:0.0024%]
[INFO] ** modbus_transaction_id:65534 (13.1068%)
[INFO] ** scada_tag:[1.0:26.0906%,0.6:20.839%,0.8:18.2282%,0.0:17.5572%,0.4:17.2792%,0.2:0.0058%]
[INFO] ** service:[0.7025755984000001:99.9976%,0.0:0.002%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.0908%,0.8139250565:20.8392%,0.8029830673999999:18.2284%,0.8149336757:17.5576%,0.8137722355:17.2794%,0.0:0.002%,0.8343113882:0.0006%,0.8059172320999999:0.0004%,0.8030136315999999:0.0004%,0.8147502904:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:87.5394%,Single Stage Single Point:12.4606%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 7, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 1 0 1] (100000,)
[INFO] Validation score: [33m0.53028[0m
[33m[INFO] metrics:[0m
loss :  2.3688553128433227
tp :  53028.0
fp :  46972.0
tn :  353028.0
fn :  46972.0
accuracy :  0.8121113777160645
precision :  0.5302799940109253
recall :  0.5302799940109253
auc :  0.8825699687004089

y_eval {0: 53028, 1: 46972}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53028     0     0     0     0]
 [46972     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2604419       0       0       0       0]
 [ 265727       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.84669[0m
[33m[INFO] metrics:[0m
loss :  0.7775546554031968
tp :  84669.0
fp :  15331.0
tn :  384669.0
fn :  15331.0
accuracy :  0.9386759996414185
precision :  0.8466899991035461
recall :  0.8466899991035461
auc :  0.9616724848747253

y_eval {0: 84669, 1: 15331}
pred {0: 100000}
[INFO] confusion matrix for file 
[[84669     0     0     0     0]
 [15331     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[2689088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2789088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2889088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[2989088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_203011_118.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9988%,1.0:0.0008%,0.0:0.0004%]
[INFO] ** type:[1.0:99.9986%,0.5:0.001%,0.0:0.0004%]
[INFO] ** i/f_name:[0.0:99.998%,0.5:0.002%]
[INFO] ** i/f_dir:[0.0:99.9982%,1.0:0.0018%]
[INFO] ** src:[0.0666666667:38.138%,0.9333333333:26.0904%,0.6666666667:18.1762%,0.3333333333:17.5892%,0.2:0.0018%,0.0:0.0016%,0.1333333333:0.0012%,0.8:0.0008%,0.5333333333:0.0006%,0.4:0.0002%]
[INFO] ** dst:[0.1764705882:43.3838%,0.9411764706:20.845%,0.8823529412000001:18.1758%,0.5294117647:17.589%,0.2941176471:0.002%,0.3529411765:0.0014%,0.0:0.0014%,0.5882352941:0.0004%,0.4705882353:0.0004%,0.23529411760000002:0.0004%,0.058823529400000005:0.0004%]
[INFO] ** proto:[0.5:99.9954%,1.0:0.0026%,0.0:0.002%]
[INFO] ** appi_name:[0.0:99.9944%,0.0384615385:0.002%,0.0769230769:0.0008%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.34615384619999995:0.0004%,0.3076923077:0.0004%,0.9615384615000001:0.0004%,0.3846153846:0.0002%,0.6153846154:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.138%,0.0:26.0904%,0.9333333333:18.1762%,0.4:17.5892%,0.5333333333:0.002%,0.0666666667:0.0018%,0.1333333333:0.0016%,0.6:0.0006%,1.0:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9944%,0.0:0.0052%,1.0:0.0004%]
[INFO] ** modbus_function_description:[0.2:49.998%,0.0:49.9964%,0.4:0.0052%,0.6:0.0004%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.0894%,0.6:20.8438%,0.8:18.1758%,0.0:17.5888%,0.4:17.294%,0.2:0.0082%]
[INFO] ** service:[0.7025755984000001:99.9954%,0.0:0.002%,0.0021633145999999997:0.0008%,0.0021476384:0.0006%,0.08391465880000001:0.0004%,0.0297847659:0.0004%,0.08394601119999999:0.0004%]
[INFO] ** s_port:[0.834280824:26.0898%,0.8139250565:20.844%,0.8029830673999999:18.1758%,0.8149336757:17.589%,0.8137722355:17.294%,0.0:0.002%,0.7435203863:0.0008%,0.0021089309:0.0008%,0.0020936488:0.0006%,0.8059172320999999:0.0006%,0.8343113882:0.0006%,0.7967938137999999:0.0004%,0.0290360046:0.0004%,0.0818051226:0.0004%,0.8030136315999999:0.0004%,0.7431230515:0.0002%,0.814841983:0.0002%]
[INFO] ** classification:[normal:90.7904%,Single Stage Multi Point:5.7378%,Single Stage Single Point:3.4718%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 7, 'classification': 3}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3089088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3189088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3289088       0       0       0       0]
 [ 281058       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.82641[0m
[33m[INFO] metrics:[0m
loss :  0.8795475680261851
tp :  82641.0
fp :  17359.0
tn :  382641.0
fn :  17359.0
accuracy :  0.9305639266967773
precision :  0.8264099955558777
recall :  0.8264099955558777
auc :  0.9566025137901306

y_eval {0: 82641, 1: 17359}
pred {0: 100000}
[INFO] confusion matrix for file 
[[82641     0     0     0     0]
 [17359     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3371729       0       0       0       0]
 [ 298417       0       0       0       0]
 [  27052       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 2 2] (100000,)
[INFO] Validation score: [33m0.71311[0m
[33m[INFO] metrics:[0m
loss :  6.349227556081415
tp :  71311.0
fp :  28689.0
tn :  371311.0
fn :  28689.0
accuracy :  0.8852441906929016
precision :  0.7131100296974182
recall :  0.7131100296974182
auc :  0.7848324775695801

y_eval {0: 71311, 2: 28689}
pred {0: 100000}
[INFO] confusion matrix for file 
[[71311     0     0     0     0]
 [    0     0     0     0     0]
 [28689     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3443040       0       0       0       0]
 [ 298417       0       0       0       0]
 [  55741       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-01_203011_118.log.part07_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9994%,0.5:0.0006%]
[INFO] ** i/f_dir:[0.0:99.9994%,1.0:0.0006%]
[INFO] ** src:[0.0666666667:38.0718%,0.9333333333:26.1174%,0.6666666667:18.2344%,0.3333333333:17.5754%,0.8:0.0008%,0.1333333333:0.0002%]
[INFO] ** dst:[0.1764705882:43.3758%,0.9411764706:20.813%,0.8823529412000001:18.2342%,0.5294117647:17.5754%,0.2941176471:0.0006%,0.0:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.999%,0.0:0.0006%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.999%,0.0384615385:0.0006%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0718%,0.0:26.1174%,0.9333333333:18.2344%,0.4:17.5754%,0.5333333333:0.0006%,0.4666666667:0.0004%]
[INFO] ** modbus_function_code:[0.9743589744:99.999%,0.0:0.001%]
[INFO] ** modbus_function_description:[0.2:49.9996%,0.0:49.9994%,0.4:0.001%]
[INFO] ** modbus_transaction_id:65301 (13.0602%)
[INFO] ** scada_tag:[1.0:26.1164%,0.6:20.813%,0.8:18.2338%,0.0:17.575%,0.4:17.2586%,0.2:0.0032%]
[INFO] ** service:[0.7025755984000001:99.999%,0.0:0.0006%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1168%,0.8139250565:20.813%,0.8029830673999999:18.234%,0.8149336757:17.5752%,0.8137722355:17.2588%,0.0:0.0006%,0.8030136315999999:0.0002%,0.8343113882:0.0002%,0.8030441959000001:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:89.2092%,Single Stage Multi Point:10.7908%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 6, 'dst': 9, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 6, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [2 0 0 ... 2 0 0] (100000,)
[INFO] Validation score: [33m0.53027[0m
[33m[INFO] metrics:[0m
loss :  10.391544135437012
tp :  53027.0
fp :  46973.0
tn :  353027.0
fn :  46973.0
accuracy :  0.8121077418327332
precision :  0.530269980430603
recall :  0.530269980430603
auc :  0.6477024555206299

y_eval {0: 53027, 2: 46973}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53027     0     0     0     0]
 [    0     0     0     0     0]
 [46973     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3496067       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 102714       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 2 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.93019[0m
[33m[INFO] metrics:[0m
loss :  1.5499162288379669
tp :  93019.0
fp :  6981.0
tn :  393019.0
fn :  6981.0
accuracy :  0.9720761179924011
precision :  0.9301900267601013
recall :  0.9301900267601013
auc :  0.9476425647735596

y_eval {0: 93019, 2: 6981}
pred {0: 100000}
[INFO] confusion matrix for file 
[[93019     0     0     0     0]
 [    0     0     0     0     0]
 [ 6981     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3589086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3689086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3789086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[3889086       0       0       0       0]
 [ 298417       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_014558_119.log.part06_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.997%,1.0:0.003%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9964%,0.5:0.0036%]
[INFO] ** i/f_dir:[0.0:99.9964%,1.0:0.0036%]
[INFO] ** src:[0.0666666667:38.0288%,0.9333333333:26.1242%,0.6666666667:18.2114%,0.3333333333:17.6294%,0.8:0.003%,0.2666666667:0.0008%,1.0:0.0006%,0.1333333333:0.0006%,0.5333333333:0.0004%,0.4:0.0004%,0.6:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.357%,0.9411764706:20.7952%,0.8823529412000001:18.2116%,0.5294117647:17.629%,0.2941176471:0.0036%,0.0:0.0012%,0.6470588235:0.0008%,0.3529411765:0.0004%,0.7058823529000001:0.0004%,0.7647058823999999:0.0004%,1.0:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9958%,0.0:0.0036%,1.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9942%,0.0384615385:0.0036%,0.7692307692:0.0008%,0.4230769231:0.0004%,0.5384615385:0.0002%,0.0769230769:0.0002%,0.11538461539999999:0.0002%,0.1538461538:0.0002%,0.4615384615:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0288%,0.0:26.1242%,0.9333333333:18.2114%,0.4:17.6294%,0.5333333333:0.0036%,0.8:0.0008%,0.7333333333:0.0006%,1.0:0.0004%,0.6:0.0004%,0.3333333333:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9942%,0.0:0.0058%]
[INFO] ** modbus_function_description:[0.2:49.9974%,0.0:49.9968%,0.4:0.0058%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.123%,0.6:20.7952%,0.8:18.211%,0.0:17.6288%,0.4:17.2336%,0.2:0.0084%]
[INFO] ** service:[0.7025755984000001:99.9942%,0.0:0.0036%,0.0208806885:0.0008%,0.0021789908:0.0004%,0.0021476384:0.0004%,0.0021633145999999997:0.0002%,0.08543524949999999:0.0002%,0.002116286:0.0002%]
[INFO] ** s_port:[0.834280824:26.1234%,0.8139250565:20.7952%,0.8029830673999999:18.2112%,0.8149336757:17.629%,0.8137722355:17.2336%,0.0:0.0036%,0.8343113882:0.0006%,0.0020936488:0.0004%,0.9310776942:0.0004%,0.8059172320999999:0.0004%,0.8147502904:0.0002%,0.814841983:0.0002%,0.15243902439999998:0.0002%,0.8344030809:0.0002%,0.0021089309:0.0002%,0.8411730545999999:0.0002%,0.7593068036:0.0002%,0.15240846019999998:0.0002%,0.8030136315999999:0.0002%,0.315972859:0.0002%,0.7586191087:0.0002%]
[INFO] ** classification:[normal:81.41%,Single Stage Single Point:18.59%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 8, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 1 0 1] (100000,)
[INFO] Validation score: [33m0.67398[0m
[33m[INFO] metrics:[0m
loss :  1.6461540570542217
tp :  67398.0
fp :  32602.0
tn :  367398.0
fn :  32602.0
accuracy :  0.8695923686027527
precision :  0.6739799976348877
recall :  0.6739799976348877
auc :  0.9184949994087219

y_eval {0: 67398, 1: 32602}
pred {0: 100000}
[INFO] confusion matrix for file 
[[67398     0     0     0     0]
 [32602     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[3956484       0       0       0       0]
 [ 331019       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 1 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.53052[0m
[33m[INFO] metrics:[0m
loss :  2.3676482962799072
tp :  53052.0
fp :  46948.0
tn :  353052.0
fn :  46948.0
accuracy :  0.812207818031311
precision :  0.5305200219154358
recall :  0.5305200219154358
auc :  0.8826299905776978

y_eval {0: 53052, 1: 46948}
pred {0: 100000}
[INFO] confusion matrix for file 
[[53052     0     0     0     0]
 [46948     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4009536       0       0       0       0]
 [ 377967       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.866[0m
[33m[INFO] metrics:[0m
loss :  0.680440102827549
tp :  86600.0
fp :  13400.0
tn :  386600.0
fn :  13400.0
accuracy :  0.946399986743927
precision :  0.8659999966621399
recall :  0.8659999966621399
auc :  0.9664999842643738

y_eval {0: 86600, 1: 13400}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86600     0     0     0     0]
 [13400     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4096136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4196136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4296136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part12_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9986%,0.0:0.0008%,1.0:0.0006%]
[INFO] ** type:[1.0:99.9984%,0.5:0.0014%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9978%,0.5:0.0022%]
[INFO] ** i/f_dir:[0.0:99.998%,1.0:0.002%]
[INFO] ** src:[0.0666666667:38.1136%,0.9333333333:26.1176%,0.6666666667:18.2158%,0.3333333333:17.5472%,0.1333333333:0.0016%,0.0:0.0014%,0.2:0.001%,0.8:0.0006%,0.2666666667:0.0004%,0.5333333333:0.0004%,0.4:0.0002%,1.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.4022%,0.9411764706:20.8284%,0.8823529412000001:18.2156%,0.5294117647:17.547%,0.2941176471:0.0022%,0.0:0.002%,0.3529411765:0.0008%,0.5882352941:0.0004%,0.7647058823999999:0.0004%,1.0:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.996%,0.0:0.0022%,1.0:0.0018%]
[INFO] ** appi_name:[0.0:99.9946%,0.0384615385:0.0022%,0.4230769231:0.0006%,0.9230769231:0.0004%,0.0769230769:0.0004%,0.1538461538:0.0002%,0.3846153846:0.0002%,1.0:0.0002%,0.34615384619999995:0.0002%,0.6153846154:0.0002%,0.3076923077:0.0002%,0.4615384615:0.0002%,0.9615384615000001:0.0002%,0.5769230769:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.1136%,0.0:26.1176%,0.9333333333:18.2158%,0.4:17.5472%,0.5333333333:0.0022%,0.1333333333:0.0014%,0.0666666667:0.001%,0.6:0.0004%,0.8:0.0004%,1.0:0.0002%,0.7333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9946%,0.0:0.0052%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.9984%,0.0:49.9962%,0.4:0.0052%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1164%,0.6:20.8284%,0.8:18.2154%,0.0:17.5466%,0.4:17.285%,0.2:0.0082%]
[INFO] ** service:[0.7025755984000001:99.9954%,0.0:0.0022%,0.0021476384:0.0006%,0.0021789908:0.0004%,0.0021633145999999997:0.0004%,0.08391465880000001:0.0004%,0.0839773636:0.0002%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1168%,0.8139250565:20.8284%,0.8029830673999999:18.2154%,0.8149336757:17.5468%,0.8137722355:17.2852%,0.0:0.0022%,0.696222263:0.0008%,0.0020936488:0.0006%,0.8059172320999999:0.0004%,0.8343113882:0.0004%,0.0021089309:0.0004%,0.0818051226:0.0004%,0.9385047986:0.0004%,0.814841983:0.0004%,0.8030441959000001:0.0002%,0.9925728957:0.0002%,0.8344030809:0.0002%,0.9705208142:0.0002%,0.8345253376999999:0.0002%,0.0290360046:0.0002%,0.8030136315999999:0.0002%]
[INFO] ** classification:[normal:99.9996%,Single Stage Multi Point:0.0004%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 9, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4396136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4496136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4596136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4696136       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109695       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.99998[0m
[33m[INFO] metrics:[0m
loss :  0.006964608313143253
tp :  99998.0
fp :  2.0
tn :  399998.0
fn :  2.0
accuracy :  0.9999920129776001
precision :  0.9999799728393555
recall :  0.9999799728393555
auc :  0.9999849796295166

y_eval {0: 99998, 2: 2}
pred {0: 100000}
[INFO] confusion matrix for file 
[[99998     0     0     0     0]
 [    0     0     0     0     0]
 [    2     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4796134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part13_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9996%,1.0:0.0004%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9994%,0.5:0.0006%]
[INFO] ** i/f_dir:[0.0:99.9994%,1.0:0.0006%]
[INFO] ** src:[0.0666666667:38.162%,0.9333333333:26.1664%,0.6666666667:18.0742%,0.3333333333:17.5958%,0.8:0.0008%,0.5333333333:0.0002%,0.7333333333:0.0002%,0.6:0.0002%,0.1333333333:0.0002%]
[INFO] ** dst:[0.1764705882:43.4352%,0.9411764706:20.8932%,0.8823529412000001:18.0744%,0.5294117647:17.5952%,0.2941176471:0.0006%,0.4705882353:0.0006%,0.0:0.0006%,0.3529411765:0.0002%]
[INFO] ** proto:[0.5:99.9986%,1.0:0.0008%,0.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9986%,0.0384615385:0.0006%,0.3076923077:0.0006%,0.4230769231:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.162%,0.0:26.1664%,0.9333333333:18.0742%,0.4:17.5958%,0.5333333333:0.0006%,0.4666666667:0.0004%,0.2666666667:0.0002%,0.6:0.0002%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9986%,0.0:0.0014%]
[INFO] ** modbus_function_description:[0.2:49.9998%,0.0:49.9988%,0.4:0.0014%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.166%,0.6:20.893%,0.8:18.0738%,0.0:17.5948%,0.4:17.2688%,0.2:0.0036%]
[INFO] ** service:[0.7025755984000001:99.9986%,0.08394601119999999:0.0006%,0.0:0.0006%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1662%,0.8139250565:20.8932%,0.8029830673999999:18.074%,0.8149336757:17.5952%,0.8137722355:17.2688%,0.0:0.0006%,0.814841983:0.0004%,0.9945442875:0.0004%,0.8059172320999999:0.0002%,0.8147502904:0.0002%,0.8030441959000001:0.0002%,0.8344030809:0.0002%,0.0020936488:0.0002%,0.8683752063:0.0002%]
[INFO] ** classification:[normal:92.8338%,Multi Stage Single Point:7.1662%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'dst': 8, 'proto': 3, 'appi_name': 4, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 4, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[4896134       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [      0       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.88734[0m
[33m[INFO] metrics:[0m
loss :  2.4972652145799996
tp :  88734.0
fp :  11266.0
tn :  388734.0
fn :  11266.0
accuracy :  0.9549478888511658
precision :  0.8873400092124939
recall :  0.8873400092124939
auc :  0.9155051112174988

y_eval {0: 88734, 3: 11266}
pred {0: 100000}
[INFO] confusion matrix for file 
[[88734     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [11266     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[4984868       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  11266       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.92435[0m
[33m[INFO] metrics:[0m
loss :  1.6790299087420106
tp :  92435.0
fp :  7565.0
tn :  392435.0
fn :  7565.0
accuracy :  0.9697391986846924
precision :  0.9243500232696533
recall :  0.9243500232696533
auc :  0.94326251745224

y_eval {0: 92435, 3: 7565}
pred {0: 100000}
[INFO] confusion matrix for file 
[[92435     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [ 7565     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5077303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5177303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  18831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.83[0m
[33m[INFO] metrics:[0m
loss :  3.764966182090938
tp :  83000.0
fp :  17000.0
tn :  383000.0
fn :  17000.0
accuracy :  0.9320096969604492
precision :  0.8299999833106995
recall :  0.8299999833106995
auc :  0.872499942779541

y_eval {0: 83000, 3: 17000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83000     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [17000     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5260303       0       0       0       0]
 [ 391367       0       0       0       0]
 [ 109697       0       0       0       0]
 [  35831       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_121729_121.log.part14_sorted-labeled.csv
[INFO] process dataset, shape: (439824, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (439824, 16)

[INFO] analyzing data
[INFO] 439824 rows
[INFO] ** orig:[0.5:99.99955%,1.0:0.00045%]
[INFO] ** type:[1.0:99.99977%,0.5:0.00023%]
[INFO] ** i/f_name:[0.0:99.99864%,0.5:0.00136%]
[INFO] ** i/f_dir:[0.0:99.99886%,1.0:0.00114%]
[INFO] ** src:[0.0666666667:38.09456%,0.9333333333:26.09703%,0.6666666667:18.22161%,0.3333333333:17.58408%,0.1333333333:0.00091%,0.5333333333:0.00068%,0.8:0.00068%,0.4:0.00023%,1.0:0.00023%]
[INFO] ** dst:[0.1764705882:43.35416%,0.9411764706:20.83674%,0.8823529412000001:18.22115%,0.5294117647:17.58385%,0.0:0.00159%,0.2941176471:0.00136%,0.23529411760000002:0.00045%,0.3529411765:0.00023%,0.5882352941:0.00023%,0.4117647059:0.00023%]
[INFO] ** proto:[0.5:99.99818%,0.0:0.00136%,1.0:0.00045%]
[INFO] ** appi_name:[0.0:99.99795%,0.0384615385:0.00136%,0.9230769231:0.00023%,0.7307692308:0.00023%,0.0769230769:0.00023%]
[INFO] ** proxy_src_ip:[0.6666666667:38.09456%,0.0:26.09703%,0.9333333333:18.22161%,0.4:17.58408%,0.5333333333:0.00136%,0.6:0.00068%,1.0:0.00023%,0.7333333333:0.00023%,0.4666666667:0.00023%]
[INFO] ** modbus_function_code:[0.9743589744:99.99795%,0.0:0.00205%]
[INFO] ** modbus_function_description:[0.2:49.99955%,0.0:49.99841%,0.4:0.00205%]
[INFO] ** modbus_transaction_id:65536 (14.90051%)
[INFO] ** scada_tag:[1.0:26.09612%,0.6:20.83652%,0.8:18.22092%,0.0:17.5834%,0.4:17.25758%,0.2:0.00546%]
[INFO] ** service:[0.7025755984000001:99.99795%,0.0:0.00136%,0.0021633145999999997:0.00023%,0.08391465880000001:0.00023%,0.0012540954:0.00023%]
[INFO] ** s_port:[0.834280824:26.09635%,0.8139250565:20.83674%,0.8029830673999999:18.22115%,0.8149336757:17.58362%,0.8137722355:17.25781%,0.0:0.00136%,0.8059172320999999:0.00068%,0.8030136315999999:0.00045%,0.8343113882:0.00045%,0.814841983:0.00045%,0.0818051226:0.00023%,0.0021089309:0.00023%,0.8030441959000001:0.00023%,0.8345253376999999:0.00023%]
[INFO] ** classification:[normal:93.34597%,Single Stage Single Point:4.48861%,Multi Stage Single Point:2.16541%]
[INFO] columns with count within 2-10 {'orig': 2, 'type': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 9, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 3}
[INFO] processing batch 0-100000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [3 0 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.86777[0m
[33m[INFO] metrics:[0m
loss :  2.2981667219409347
tp :  86777.0
fp :  13223.0
tn :  386777.0
fn :  13223.0
accuracy :  0.9471138119697571
precision :  0.8677700161933899
recall :  0.8677700161933899
auc :  0.9193224906921387

y_eval {0: 86777, 1: 3699, 3: 9524}
pred {0: 100000}
[INFO] confusion matrix for file 
[[86777     0     0     0     0]
 [ 3699     0     0     0     0]
 [    0     0     0     0     0]
 [ 9524     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5347080       0       0       0       0]
 [ 395066       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.83957[0m
[33m[INFO] metrics:[0m
loss :  0.8133628131952881
tp :  83957.0
fp :  16043.0
tn :  383957.0
fn :  16043.0
accuracy :  0.9358352422714233
precision :  0.8395699858665466
recall :  0.8395699858665466
auc :  0.9598925113677979

y_eval {0: 83957, 1: 16043}
pred {0: 100000}
[INFO] confusion matrix for file 
[[83957     0     0     0     0]
 [16043     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[5431037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5531037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/439824
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5631037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/439824
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part03_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9976%,1.0:0.002%,0.0:0.0004%]
[INFO] ** type:[1.0:99.9988%,0.5:0.001%,0.0:0.0002%]
[INFO] ** i/f_name:[0.0:99.9944%,0.5:0.0056%]
[INFO] ** i/f_dir:[0.0:99.9946%,1.0:0.0054%]
[INFO] ** src:[0.0666666667:38.2234%,0.9333333333:26.124%,0.6666666667:18.075%,0.3333333333:17.571%,0.1333333333:0.0036%,0.8:0.0022%,0.2666666667:0.0004%,0.2:0.0002%,0.0:0.0002%]
[INFO] ** dst:[0.1764705882:43.4342%,0.9411764706:20.913%,0.8823529412000001:18.0748%,0.5294117647:17.5708%,0.2941176471:0.0056%,0.0:0.0006%,0.5882352941:0.0004%,0.4705882353:0.0002%,0.23529411760000002:0.0002%,0.058823529400000005:0.0002%]
[INFO] ** proto:[0.5:99.9936%,0.0:0.0056%,1.0:0.0008%]
[INFO] ** appi_name:[0.0:99.9934%,0.0384615385:0.0056%,0.9230769231:0.0004%,0.34615384619999995:0.0002%,0.3076923077:0.0002%,0.9615384615000001:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.2234%,0.0:26.124%,0.9333333333:18.075%,0.4:17.571%,0.5333333333:0.0056%,0.8:0.0004%,0.4666666667:0.0002%,0.0666666667:0.0002%,0.1333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9934%,0.0:0.0064%,1.0:0.0002%]
[INFO] ** modbus_function_description:[0.2:49.997%,0.0:49.9964%,0.4:0.0064%,0.6:0.0002%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1234%,0.6:20.9128%,0.8:18.0748%,0.0:17.5704%,0.4:17.3102%,0.2:0.0084%]
[INFO] ** service:[0.7025755984000001:99.9936%,0.0:0.0056%,0.08391465880000001:0.0004%,0.0297847659:0.0002%,0.08394601119999999:0.0002%]
[INFO] ** s_port:[0.834280824:26.1238%,0.8139250565:20.913%,0.8029830673999999:18.0748%,0.8149336757:17.5706%,0.8137722355:17.3104%,0.0:0.0056%,0.0818051226:0.0004%,0.814841983:0.0004%,0.9715599976:0.0002%,0.8030136315999999:0.0002%,0.696222263:0.0002%,0.9535729568000001:0.0002%,0.8345253376999999:0.0002%]
[INFO] ** classification:[normal:94.9296%,Single Stage Single Point:5.0704%]
[INFO] columns with count within 2-10 {'orig': 3, 'type': 3, 'i/f_name': 2, 'i/f_dir': 2, 'src': 9, 'proto': 3, 'appi_name': 6, 'proxy_src_ip': 9, 'modbus_function_code': 3, 'modbus_function_description': 4, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5731037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5831037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[5931037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6031037       0       0       0       0]
 [ 411109       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.74648[0m
[33m[INFO] metrics:[0m
loss :  1.2815344279000163
tp :  74648.0
fp :  25352.0
tn :  374648.0
fn :  25352.0
accuracy :  0.8986006379127502
precision :  0.7464799880981445
recall :  0.7464799880981445
auc :  0.9366199970245361

y_eval {0: 74648, 1: 25352}
pred {0: 100000}
[INFO] confusion matrix for file 
[[74648     0     0     0     0]
 [25352     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6105685       0       0       0       0]
 [ 436461       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part04_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.995%,1.0:0.005%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9944%,0.5:0.0056%]
[INFO] ** i/f_dir:[0.0:99.9944%,1.0:0.0056%]
[INFO] ** src:[0.0666666667:38.203%,0.9333333333:26.1368%,0.6666666667:18.1014%,0.3333333333:17.5508%,0.8:0.005%,1.0:0.0008%,0.5333333333:0.0006%,0.1333333333:0.0006%,0.2666666667:0.0004%,0.4:0.0004%,0.6:0.0002%]
[INFO] ** dst:[0.1764705882:43.4462%,0.9411764706:20.893%,0.8823529412000001:18.1012%,0.5294117647:17.5504%,0.2941176471:0.0056%,0.0:0.0016%,0.6470588235:0.0008%,0.3529411765:0.0006%,0.7058823529000001:0.0004%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.9938%,0.0:0.0056%,1.0:0.0006%]
[INFO] ** appi_name:[0.0:99.9926%,0.0384615385:0.0056%,0.7692307692:0.0008%,0.0769230769:0.0004%,0.5384615385:0.0002%,0.4230769231:0.0002%,0.11538461539999999:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.203%,0.0:26.1368%,0.9333333333:18.1014%,0.4:17.5508%,0.5333333333:0.0056%,0.7333333333:0.0008%,0.6:0.0006%,1.0:0.0004%,0.8:0.0004%,0.3333333333:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9926%,0.0:0.0074%]
[INFO] ** modbus_function_description:[0.2:49.9972%,0.0:49.9954%,0.4:0.0074%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1358%,0.6:20.8928%,0.8:18.1008%,0.0:17.55%,0.4:17.31%,0.2:0.0106%]
[INFO] ** service:[0.7025755984000001:99.9926%,0.0:0.0056%,0.0208806885:0.0008%,0.0021633145999999997:0.0004%,0.08543524949999999:0.0002%,0.002116286:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.136%,0.8139250565:20.893%,0.8029830673999999:18.101%,0.8149336757:17.5502%,0.8137722355:17.31%,0.0:0.0056%,0.8343113882:0.0006%,0.8059172320999999:0.0006%,0.0021089309:0.0004%,0.814841983:0.0004%,0.8147502904:0.0002%,0.7593068036:0.0002%,0.7586191087:0.0002%,0.15243902439999998:0.0002%,0.15240846019999998:0.0002%,0.8411730545999999:0.0002%,0.8030136315999999:0.0002%,0.8345253376999999:0.0002%,0.0020936488:0.0002%,0.315972859:0.0002%,0.8030441959000001:0.0002%]
[INFO] ** classification:[normal:64.3482%,Single Stage Single Point:35.6518%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'proto': 3, 'appi_name': 7, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 7, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64457[0m
[33m[INFO] metrics:[0m
loss :  1.7940638995742797
tp :  64457.0
fp :  35543.0
tn :  364457.0
fn :  35543.0
accuracy :  0.8578357100486755
precision :  0.644569993019104
recall :  0.644569993019104
auc :  0.9111424684524536

y_eval {0: 64457, 1: 35543}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64457     0     0     0     0]
 [35543     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6170142       0       0       0       0]
 [ 472004       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64588[0m
[33m[INFO] metrics:[0m
loss :  1.7874756021499634
tp :  64588.0
fp :  35412.0
tn :  364588.0
fn :  35412.0
accuracy :  0.8583595156669617
precision :  0.6458799839019775
recall :  0.6458799839019775
auc :  0.9114699959754944

y_eval {0: 64588, 1: 35412}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64588     0     0     0     0]
 [35412     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6234730       0       0       0       0]
 [ 507416       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 1 0 ... 1 0 0] (100000,)
[INFO] Validation score: [33m0.64276[0m
[33m[INFO] metrics:[0m
loss :  1.8031668184280396
tp :  64276.0
fp :  35724.0
tn :  364276.0
fn :  35724.0
accuracy :  0.8571111559867859
precision :  0.6427599787712097
recall :  0.6427599787712097
auc :  0.9106900095939636

y_eval {0: 64276, 1: 35724}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64276     0     0     0     0]
 [35724     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6299006       0       0       0       0]
 [ 543140       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 1 1 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.64281[0m
[33m[INFO] metrics:[0m
loss :  1.8029153546905519
tp :  64281.0
fp :  35719.0
tn :  364281.0
fn :  35719.0
accuracy :  0.8571314215660095
precision :  0.6428099870681763
recall :  0.6428099870681763
auc :  0.9107024669647217

y_eval {0: 64281, 1: 35719}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64281     0     0     0     0]
 [35719     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6363287       0       0       0       0]
 [ 578859       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 1 1 1] (100000,)
[INFO] Validation score: [33m0.64139[0m
[33m[INFO] metrics:[0m
loss :  1.8100568710708618
tp :  64139.0
fp :  35861.0
tn :  364139.0
fn :  35861.0
accuracy :  0.8565624356269836
precision :  0.6413900256156921
recall :  0.6413900256156921
auc :  0.9103475213050842

y_eval {0: 64139, 1: 35861}
pred {0: 100000}
[INFO] confusion matrix for file 
[[64139     0     0     0     0]
 [35861     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6427426       0       0       0       0]
 [ 614720       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] reading file data/SWaT2015-Attack-Files-v0.4-minmax/eval/2016-01-02_172943_122.log.part05_sorted-labeled.csv
[INFO] process dataset, shape: (500000, 18)
[33mdropping column: modbus_value[0m
dropping all time related columns...
[33mdropping column: unixtime[0m
[INFO] columns: Index(['orig', 'type', 'i/f_name', 'i/f_dir', 'src', 'dst', 'proto',
       'appi_name', 'proxy_src_ip', 'modbus_function_code',
       'modbus_function_description', 'modbus_transaction_id', 'scada_tag',
       'service', 's_port', 'classification'],
      dtype='object')
[INFO] analyze dataset: (500000, 16)

[INFO] analyzing data
[INFO] 500000 rows
[INFO] ** orig:[0.5:99.9992%,1.0:0.0008%]
[INFO] ** type:[1.0:100.0%]
[INFO] ** i/f_name:[0.0:99.9984%,0.5:0.0016%]
[INFO] ** i/f_dir:[0.0:99.9984%,1.0:0.0016%]
[INFO] ** src:[0.0666666667:38.0648%,0.9333333333:26.1164%,0.6666666667:18.2044%,0.3333333333:17.6118%,0.8:0.001%,0.1333333333:0.0008%,0.2666666667:0.0004%,1.0:0.0004%]
[INFO] ** dst:[0.1764705882:43.368%,0.9411764706:20.8128%,0.8823529412000001:18.2044%,0.5294117647:17.6114%,0.2941176471:0.0016%,0.0:0.0006%,0.6470588235:0.0004%,0.3529411765:0.0002%,0.4705882353:0.0002%,0.4117647059:0.0002%,0.23529411760000002:0.0002%]
[INFO] ** proto:[0.5:99.998%,0.0:0.0016%,1.0:0.0004%]
[INFO] ** appi_name:[0.0:99.9974%,0.0384615385:0.0016%,0.5384615385:0.0006%,0.4230769231:0.0002%,0.3076923077:0.0002%]
[INFO] ** proxy_src_ip:[0.6666666667:38.0648%,0.0:26.1164%,0.9333333333:18.2044%,0.4:17.6118%,0.5333333333:0.0016%,0.7333333333:0.0004%,0.8:0.0004%,0.4666666667:0.0002%]
[INFO] ** modbus_function_code:[0.9743589744:99.9974%,0.0:0.0026%]
[INFO] ** modbus_function_description:[0.2:49.9992%,0.0:49.9982%,0.4:0.0026%]
[INFO] ** modbus_transaction_id:65536 (13.1072%)
[INFO] ** scada_tag:[1.0:26.1154%,0.6:20.8126%,0.8:18.204%,0.0:17.6112%,0.4:17.2518%,0.2:0.005%]
[INFO] ** service:[0.7025755984000001:99.9974%,0.0:0.0016%,0.002116286:0.0006%,0.08394601119999999:0.0002%,0.0021476384:0.0002%]
[INFO] ** s_port:[0.834280824:26.1158%,0.8139250565:20.8128%,0.8029830673999999:18.204%,0.8149336757:17.6114%,0.8137722355:17.252%,0.0:0.0016%,0.8343113882:0.0004%,0.8147502904:0.0002%,0.7853933615:0.0002%,0.8030136315999999:0.0002%,0.9882022128:0.0002%,0.814841983:0.0002%,0.8344030809:0.0002%,0.9406137294:0.0002%,0.0020936488:0.0002%,0.7943945229:0.0002%,0.8030441959000001:0.0002%]
[INFO] ** classification:[normal:97.0224%,Single Stage Single Point:2.9776%]
[INFO] columns with count within 2-10 {'orig': 2, 'i/f_name': 2, 'i/f_dir': 2, 'src': 8, 'proto': 3, 'appi_name': 5, 'proxy_src_ip': 8, 'modbus_function_code': 2, 'modbus_function_description': 3, 'scada_tag': 6, 'service': 5, 'classification': 2}
[INFO] processing batch 0-100000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [1 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m0.85112[0m
[33m[INFO] metrics:[0m
loss :  0.755275139747262
tp :  85112.0
fp :  14888.0
tn :  385112.0
fn :  14888.0
accuracy :  0.9404467940330505
precision :  0.8511199951171875
recall :  0.8511199951171875
auc :  0.9627799987792969

y_eval {0: 85112, 1: 14888}
pred {0: 100000}
[INFO] confusion matrix for file 
[[85112     0     0     0     0]
 [14888     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]
 [    0     0     0     0     0]]
[INFO] confusion matrix after adding it to total:
[[6512538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 100000-200000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6612538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 200000-300000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6712538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 300000-400000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6812538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
[INFO] processing batch 400000-500000/500000
[33m[INFO] measuring accuracy...[0m
x_test.shape: (100000, 15)
y_eval [0 0 0 ... 0 0 0] (100000,)
[INFO] Validation score: [33m1.0[0m
[33m[INFO] metrics:[0m
loss :  0.0065224384889006615
tp :  100000.0
fp :  0.0
tn :  400000.0
fn :  0.0
accuracy :  1.0
precision :  1.0
recall :  1.0
auc :  1.0

y_eval {0: 100000}
pred {0: 100000}
[INFO] confusion matrix for file 
[[100000      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]
 [     0      0      0      0      0]]
[INFO] confusion matrix after adding it to total:
[[6912538       0       0       0       0]
 [ 629608       0       0       0       0]
 [ 109697       0       0       0       0]
 [  45355       0       0       0       0]
 [ 202802       0       0       0       0]]
--- 220.34510326385498 seconds ---
